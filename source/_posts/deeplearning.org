#+TITLE:          Deep Learning
#+AUTHOR:         Kyle Three Stones
#+DATE:           <2018-07-12 Thu 07:19>
#+EMAIL:          kyleemail@163.com
#+OPTIONS:        H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t f:t tex:t
#+HTML_MATHJAX:   align: left indent: 5em tagside: left font: Neo-Euler
#+STARTUP:        latexpreview
#+TAGS:           深度学习, 机器学习
#+CATEGORIES:     深度学习

1989 年 Robert Hecht-Nielsen 证明了万能逼近定理：对于任何闭区间的一个连续函数都可以用一个隐含层的 BP 网络来逼近（完成任
意m 维到 n 维的映射）。

** 神经网络和深度学习

*** 神经网络概论
ReLu: rectified linear unit ，修正线性单元；修正指的是取不小于 0 的值。

每个神经元类似一个乐高积木(Lego brick) ，将许多神经元堆叠在一起就形成了一个较大的神经网络。而且并不会认为决定每个神经元
的作用，而是由神经网络自己决定每个神经元的作用。如果给神经网络足够多的训练数据，其非常擅长计算从输入到输出的精确映射。神
经网络在监督学习中效果很好很强大。

+ 结构化数据(structured data)：每个特征都有清晰、明确有意义的定义；比如房屋的面积，人的身高等
+ 非结构化数据(unstructured data)：特征无法精确定义；比如图像的像素点，音频，文字
人类很擅长处理结构化的数据，但机器很不擅长。而归功于深度学习，使得机器在非结构化数据的处理有了明显的提高；但是现在比较挣
钱的仍然是让机器处理结构化数据，如广告投放、理解处理公司的海量数据并进行预测等。吴恩达希望设计的网络可以处理结构化数据也
可以处理非结构化的数据。

神经网络有不同的种类，有用于处理图像的 CNN(Convolution Neural Network)、处理一维序列的 RNN(Recurrent Neural Network)、以
及自动驾驶中用于处理雷达数据的混合神经网络(Hybrid Neural Network)[对于复杂的问题，需要自行构建网络的架构；和机器学习中的
算法一样，针对具体的问题，需要去做具体的优化，而不是一成不变的使用基本的算法]

scale 使得神经网络在最近流行起来，这里的 scale 并不单单指神经网络的规模，还包括数据的规模。当训练样本不是很大的时候，神
经网络与传统的机器学习算法之间的优劣并不明显，此时主要取决有人为设计算法的技巧和能力以及算法处理的细节，可能一个设计良好
的 SVM 算法结果要由于一个神经网络的效果；但是随着样本量不断变大，传统的机器学习算法的性能会在在达到一定的性能之后效果变
无法继续提升，而神经网络此时的效果将明显领先与传统的算法[需要很大的样本，且网络的规模越大，性能越好]。数据、计算能力、算
法都促使了深度学习的发展；算法的主要改进都在加快算法的速度，比如使用 ReLU 函数替代 sigmoid 函数就大大加快了算法的训练速
度，因为 sigmoid 函数在自变量趋向于正负无穷大的时候，导数趋向于 0，而使用梯度下降法，梯度的减小将使得参数的变化变得缓慢，
从而学习将变得缓慢；而 ReLU 函数右侧的斜率始终为 1，由于斜率不会逐渐趋向于 0，使得算法训练速度大大提高。速度的提升使得我
们可以训练大型的网络或者在一定的时间内完成网络的训练。而且训练神经网络的过程一般是 idea - code - experiment - idea 不断
循环，迭代的更快使得验证自己的想法更加快速得到验证，将有机会取验证更多的想法，从而更有可能找到合适的结果。


*** 神经网络基础

一张彩色图像像素点由 RGB 三个通道组成，作为神经网络的输入时，将三个矩阵都转换成向量并拼接起来组成一个列向量 \(x^{(i)}
\in \mathbb{R}^{n_x}\)，列向量中先是红色通道的所有像素点，然后是绿色通道的所有像素点，最后是蓝色通道的所有像素点。m 个训
练样本 \(\{ (x^{(1)},y^{(1)}), (x^{(2)},y^{(2)}), \cdots, (x^{(i)},y^{(i)}) \}\) ；同时使用 \(X \in \mathbb{R}^{n_x
\times m} \) 表示所有的训练样本\[X= \left[ \begin{array}{cccc} | & | & & | \\ x^{(1)} & x^{(2)} & \cdots & x^{(m)} \\ |
& | & & | \end{array} \right] \] 相比于让每个样本按行向量堆叠，在神经网络中构建过程会简单很多。\(y^{(i)} \in \{0,1\}\)
同时将所有的标签组成一个行向量 \(Y \in \mathbb{R}^{1 \times m}\) \[ Y = [ y^{(1)}, y^{(2)}, \cdots, y^{(m)} ]\] 。在
Python 中使用 (n,m) = X.shape 和 (1,m) = Y.shape 得到向量的维数（使用的是 numpy 库中的array）。并且在神经网络中，使用权
重 w 和基 b 来表示参数，而不使用 \(\theta\) 来整体表示参数。且在程序中使用变量 dw 和 db 来表示 cost function 对 w 和 b
的导数。

loss(error) function 定义的是单个样本的误差；cost function 衡量的是在所有训练样本上的性能，定义为所有样本的 loss
function 之和的平均。算法通过 cost function 来求解参数 w 和 b 。

梯度下降法几乎对任何初始化方法都有效，如初始化为 0 或者使用随机值进行初始化。

导数，也就是斜率，定义为自变量在某一点产生一点变化，导致因变量变化值相对于自变量变化值的倍数。导数在不同的点可能会有不同
的值，由此组成了导函数。

计算图(computation graph) 用于精确的描述反向传播算法。图中每个节点表示一个变量（变量可以是标量、向量、矩阵、张量或者其他
类型的变量），操作(operation)指一个或多个变量的简单函数[深度学习书中定义一个操作仅返回单个输出变量]。

由于计算反向传播的过程中很多都在求解最终的损失函数(cost function)对中间某个变量的导数，如 \(\frac{d}{dw_1}J\) ，所以一般
会将该表达式简写成 \(dw_1\) 。

向量化可以大大提高运算速度。 CPU 和 GPU 都有并行化的指令，称为 SIMD(single instruction multiple data)[单指令流多数据流]。
CPU 也有并行化指令，只是没有 GPU 那么擅长。使用 Python 的 numpy 库函数能够充分利用并行化操作来提高计算速度，这些库函数都
进行了很好的运用了并行化指令。 *原则，如果有其他的方法，就不要使用 for 循环。*

将每个样本 \(x^{(i)}\) 看成一个列向量，然后按列把所有样本堆叠起来组成一个大的矩阵 X 。权重 \(W^T\) 视为行向量，可以让两
者直接相乘得到 \(W^T X\) ，而不再是逐个样本去计算。

#+BEGIN_SRC python
import numpy as np
A = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12] ])
print(A.shape)
cal = A.sum(axis=0) # 按列求和
row = A.sum(axis=1) # 按行求和
# numpy 中有广播机制，可以自动扩展向量（按行或者列复制 n 次）
percentage = 100 * A / (cal.reshape(1,4) # 最好使用 reshape 函数确保
# 矩阵的维数正确，该函数调用成本很低 O(1)

a = np.random.randn(5) # 
print(a.shape) # (5,) 是一个秩为 1 的数组，但即不是行向量，也不是列向量；永远不要使用，否则会产生一些很奇怪的 bug

a = np.random.randn(5,1) # 列向量
a.shape # (5,1)
a = np.random.randn(1,5) # 行向量
a.shape # (1,5)

assert(a.shape == (5,1)) # 多多验证
a = a.reshape((5,1))

db = np.sum(dz, axis = 1, keepdims = True) # keepdims 用于阻止 numpy 生成秩为 1 的数组
#+END_SRC

*** 两层神经元网络

\(z^{[i]}\) 用于表示网络的第 i 层。

输入层、隐层、输出层。约定俗成， *计算网络的层数的时候，不算输入层，输入层称为第 0 层。*
\(a^{[0]} = X \) 表示输入层 (a 是 activation)， \(a^{[1]}\) 表示第一个隐层
\[a^{[1]} = \left[ \begin{array}{c} a_1^{[1]} \\ a_2^{[1]} \\ \ldots \\ a_{m1}^{[1]} \end{array} \right] \]

\[ z_1^{[1]} = {(w_1^{[1]})}^T x + b_1^{[1]}, \ a_1 = sigmoid(z_1^{[1]}) \]
\[ z_2^{[1]} = {w_2^{[1]}}^T x + b_2^{[1]}, \ a_2 = sigmoid(z_2^{[1]}) \]
\[ z_3^{[1]} = {w_3^{[1]}}^T x + b_3^{[1]}, \ a_3 = sigmoid(z_3^{[1]}) \]
\[ z_4^{[1]} = {w_4^{[1]}}^T x + b_4^{[1]}, \ a_4 = sigmoid(z_4^{[1]}) \]

将网络中每一层的相同变量按行堆叠起来组成一个列向量，如 w, b, z, a ，便可以使用向量化计算来提高速度。

\[ W^{[i]} = \left[ \begin{array}{ccc} -- & {w_1^{[i]}}^T & -- \\ -- & {w_2^{[i]}}^T & -- \\ 
& \vdots & \\ -- & {w_l^{[i]}}^T & -- \end{array} \right] \]
\[ b^{[i]} = \left[ \begin{array}{c} b_1^{[i]} \\ b_2^{[i]} \\ \vdots \\ b_l^{[i]} \end{array} \right] \]
\[ z^{[i]} = \left[ \begin{array}{c} z_1^{[i]} \\ z_2^{[i]} \\ \vdots \\ z_l^{[i]} \end{array} \right] \]
\[ a^{[i]} = \left[ \begin{array}{c} a_1^{[i]} \\ a_2^{[i]} \\ \vdots \\ a_l^{[i]} \end{array} \right] \]

得到向量化公式

\[ z^{[i]} = W^{[i]} a^{[i-1]} + b^{[i]} \]
\[ a^{[i]} = np.sigmoid(z^{[i]}) \]

多个训练样本
\[ z^{[i](l)} = W^{[i]} a^{[i-1](l)} + b^{[i]} \]
\[ a^{[i](l)} = sigmoid(z^{[i](l)}) \]

不同训练样本的值按列堆叠

\[X= \left[ \begin{array}{cccc} | & | & & | \\ x^{(1)} & x^{(2)} & \cdots & x^{(m)} \\ |
& | & & | \end{array} \right] \]

\[Z^{[i]} = \left[ \begin{array}{cccc} | & | & & | \\ z^{[i](1)} & z^{[i](2)} & \cdots & z^{[i](m)} \\ |
& | & & | \end{array} \right] \]

\[A^{[i]} = \left[ \begin{array}{cccc} | & | & & | \\ a^{[i](1)} & a^{[i](2)} & \cdots & a^{[i](m)} \\ |
& | & & | \end{array} \right] \]

A 、Z 的水平方向表示的是不同的样本，垂直方向表示的不同网络某一层中的不同节点。

\[ Z^{[i]} = W[i]A[i-1] + b^{[i]}\]
\[ A^{[i]} = sigmoid(Z^{[i]}) \]

如果把输入按列堆叠，输出也将按列堆叠。

**** Activation function
激活函数，不同网络层的激活函数可以不同。

\begin{align*}
sigmoid(z) & = \frac{1}{ 1-e^{-z} } \\
tanh(z) & = \frac{ e^z - e^{-z} }{ e^z + e^{-z} }, \quad \text{a shifted version of sigmoid} \\
ReLU(z) & = \max(0,z) \\
leaky ReLU(z) & = \max(0.01z,z) \\
& = \left\{ \begin{array}{} 0.01z, & z < 0 \\ z, & z \geq 0 \end{array} \right.
\end{align*}

tanh 函数几乎总是比 死规模的 sigmoid 函数的效果要好，因为其均值为 0 ？更有利于后面网络层的学习，类似于将输入样本的均值归
一化到 0 一样。网络的输出层（二分类）可以使用 sigmoid 函数，其他的时候几乎不要使用。但是两者当 z 很大或者很小的时候，两
者的梯度变得很小，将减慢网络的学习速度。深度神经网络中，一般都只使用 ReLU 激活函数。另外 leaky ReLU 理论上效果会更好，不
会一半的导数为 0 ，但实际上很少使用。

*为什么需要激活函数：* 如果没有激活函数或者激活函数是线性的，那么无论网络层数有多少，其实际上都只是在做线性回归。两个或
者多个线性函数的叠加仍然是线性函数。所以使用非线性的激活函数非常重要。

*激活函数求导：* 

\begin{align*}
g(z) & = \frac{1}{1 + e^{-z}} \\
g'(z) & = g(z)(1-g(z)), \quad \text{compute quickly when g(z) is know} \\
g(z) & = tanh(z) \\
g'(z) & = 1-(tanh(z))^2 \\
g(z) & = max(0,z) \\
g'(z) & = \left\{ \begin{array}{} 0 & if \ z < 0 \\ 1 & if \ z > 0 \\ undefined & if \ z = 0 \end{array} \right. \\
g(z) & = max(0.01z,z) \\
g'(z) & = \left\{ \begin{array}{} 0.01 & if \ z < 0 \\ 1 & if \ z > 0 \\ undefined & if \ z = 0 \end{array} \right.
\end{align*}

实际中使用 ReLU 或者 leaky ReLU 函数时，z 为 0 的概率很小很小，所以使用时，让激活函数的导数在 0 点等于 0 或者 1 都可以，
并不会影响结果。

**** 反向传播

利用计算图(computation graph)表示前向传播和反向传播。前向传播时，需要计算网络的输出，每经过一个节点，都需要乘以该节点的
函数表达式来得到该神经元的输出值，然后继续向前传播；反向传播时，需要计算的是参数的导数，根据导数的链式法则，每经过一个神
经元，都需要乘以该神经元函数表达式对需要求导变量的偏导数，然后继续反向传播。无论前向传播还是反向传播，都是一层一层的计算，
根据前一层的结果来求得本层节点的值，只是前向传播时乘以的是节点的函数表达式，而反向传播时乘以的是偏导数。

比如求取导数 dz ，并且已知 \(a = g(z)\)
\[ dz = da \cdot g'(z) \]

前向传播过程中计算激活函数时，是将矩阵中的每个元素都乘以激活函数的表达式，也就是逐元素相乘；反向传播乘以激活函数的导数时
也要逐元素相乘。

无论前向传播还是反向传播，计算过程中确保矩阵的维数相同，将避免很多问题。

权重的维数
\[ W^{[l]}.shape = (n^{[l]},n^{[l-1]}) \]
\[ Z^{[l]}.shape = (n^{[l]}) \]

某个向量 v 和其导数 dv 的维数必定总是相同的。

**** 随机初始化权重

在深度学习中，必须使用随机初始化的方式来初始化权重。假如将所有的权重都初始化为 0，那么前向传播时，由于对称性每个神经元节
点的值都会相同，反向传播时，得到的每个神经元节点权重的导数也相同，从而导致所有神经元的权重都是相同的。而实际上我们希望不
同的神经元使用不同的权重，来计算不同的特征。这将导致神经网络无法工作。

#+BEGIN_SRC python
# 通常把权重初始化称非常小的随机数；防止直接达到 sigmoid 函数梯度很小的地方
W1 = np.random.randn(2,2) * 0.01 #
b1 = np.zeros(2,1) # 无需随机初始化
#+END_SRC

*** 深层神经元网络

算法的复杂性来自于数据而不是代码，所以很多时候会惊讶，这么简单的代码居然实现了这么 6 的功能。

发现一些问题只有深层网络可以求解，浅层网络无法解决。下面有两个解释使用深层网络的原因：

1. 使用深层网络检测人脸，开始的网络层检测的是脸部的边缘（横线、竖线、不同角度的斜线），之后的网络层检测的是五官（由浅层
   网络组合成眼睛、鼻子、嘴巴等部位），随后的网络层组合不同的五官来组成整张脸从而识别身份。语音类似
2. 复杂的数学函数，如果使用多层网络来学习表示，那么每个节点只需要是一个很简单的函数，将这些简单的函数组成一个深层网络，
   就可以很好的表示该复杂函数；而如果只使用一个隐层，那么隐层函数将会非常复杂，可能需要指数级个数的节点。

逐样本计算公式：

\begin{align*}
z^{[l]} & = W^{[l]} a^{[l-1]} + b^{[l]} \\
a^{[l]} & = g^{[l]} (z^{[l]} \\

dz^{[l]} & = da^{[l]} * {g^{[l]}}' (z^{[l]}) \quad \text{element wise product} \\
dW^{[l]} & = dz^{[l]} \cdot a^{[l-1]} \\
db^{[l]} & = dz^{[l]} \\
da^{[l-1]} & = {W^{[l]}}^T \cdot dz^{[l]}
\end{align*}

向量化计算所有样本公式：

\begin{align*}
Z^{[l]} & = W^{[l]} A^{[l-1]} + b^{[l]} \\
A^{[l]} & = g^{[l]} (Z^{[l]}) \\

dZ^{[l]} & = dA^{[l]} * {g^{[l]}}' (Z^{[l]}) \quad \text{element wise} \\
dW^{[l]} & = dZ^{[l]} \cdot {A^{[l-1]}}^T \\
dB^{[l]} & = \frac{1}{m} np.sum(dZ^{[l]}, axis=1, keepdims=True) \\
dA^{[l-1]} & = {W^{[l]}}^T \cdot dZ^{[l]}
\end{align*}


#+BEGIN_SRC python
# Talk is cheap, show me the code
import numpy as np
# ReLU 激活函数
def ReLU(Z):
    # ReLU(z) = max(0,z)

    # numpy broadcoast
    res = np.maximum(Z, 0)

    return res

# ReLU 激活函数的导数
def dReLU(Z):
    # 所有小于 0 的值导数为 0
    dZ = np.maximum(Z, 0)
    # 所有大于 0 的值导数为 1
    dZ[Z > 0] = 1

    return dZ

def forword(Apl, Wl, bl, g):
    '''
    Apl: 上一层的节点的输出
    Wl: 本层节点的权重
    bl: 本层节点的偏移
    g: 本层网络的激活函数

    '''

    # Apl.shape[1] = bl.shape[1] = minibatch size
    assert(bl.shape[1] == 1 or Apl.shape[1] == bl.shape[1])
    # Wl.shape = (Al.shape[0], Apl.shape[0])
    assert(Apl.shape[0] == Wl.shape[1])
    # A 的行数等于 W 的行数，列数等于 Apl 的列数

    # Z^{[l]} & = W^{[l]} A^{[l-1]} + b^{[l]}
    # A^{[l]} & = g^{[l]} (Z^{[l]})
    Zl = np.dot(Wl, Apl) + bl
    Al = g(Zl)

    return Al,Zl


def backword(dAl, Wl, Zl, dgl, Apl):
    '''
    dAl: 本层节点的导数
    Wl: 本层节点的权重
    Zl: 本层节点激活函数的输入
    dgl: 本层网络激活函数的导函数
    Apl: 本层节点的输出
    '''

    assert(dAl.shape == Zl.shape)
    assert(Wl.shape == (dAl.shape[0], Apl.shape[0]))
    assert(dAl.shape[1] == Apl.shape[1])

    # dZ^{[l]} & = dA^{[l]} * {g^{[l]}}' (Z^{[l]}) \quad \text{element wise product} \\
    # dW^{[l]} & = dZ^{[l]} \cdot {A^{[l-1]}}^T \\
    # dB^{[l]} & = \frac{1}{m} np.sum(dZ^{[l]}, axis=1, keepdims=True) \\
    # dA^{[l-1]} & = {W^{[l]}}^T \cdot dZ^{[l]}
    dZl = np.multiply(dAl, dgl(Zl)) # element wise product
    dWl = np.dot(dZl, Apl.transpose())
    dbl = np.sum(dZl, axis = 1, keepdims = True) / dAl.shape[1]
    dApl = np.dot(Wl.transpose(), dZl)

    return dApl,dWl,dbl


Apl = np.random.randn(5,8)
Wl = np.random.randn(9,5) * 0.01
bl = np.random.randn(9,1)

Al,Zl = forword(Apl, Wl, bl, ReLU)
print("Al")
print(Al)

print("Zl")
print(Zl)

dAl = np.random.randn(9,8)
dApl,dWl,dbl = backword(dAl, Wl, Zl, dReLU, Apl)

print("dApl")
print(dApl)
print("dWl")
print(dWl)
print("dbl")
print(dbl)

#+END_SRC


**** 核对矩阵的维数

拿出纸和笔，手算一下每个矩阵的维数，可以大大减小网络的 bug 。

| 参数         | 维数                     |
|--------------+--------------------------|
| \(W^{[l]}\)  | \((n^{[l]}, n^{[l-1]})\) |
| \(dW^{[l]}\) | \((n^{[l]}, n^{[l-1]})\) |
| \(b^{[l]}\)  | \((n^{[l]}, 1)\)         |
| \(B^{[l]}\)  | \((n^{[l]}, m)\)         |
| \(db^{[l]}\) | \((n^{[l]}, 1)\)         |
| \(dB^{[l]}\) | \((n^{[l]}, m)\)         |
| \(z^{[l]}\)  | \((n^{[l]}, 1)\)         |
| \(Z^{[l]}\)  | \((n^{[l]}, m)\)         |
| \(a^{[l]}\)  | \((n^{[l]}, 1)\)         |
| \(A^{[l]}\)  | \((n^{[l]}, m)\)         |

无论是否向量化同时计算多个样本，权重 W 的维数都是一样的。

**** Hyperparamter

*超参：* 学习速率、迭代次数、隐层数、每一层节点的个数、激活函数、minibatch size、momentum、regularization parameters

这些超参需要手动设置，并且这些参数经影响你参数的最终结果。而预先很难知道最优的超参是什么，所以必须尝试各种参数
（依据 idea->code->experiment 循环），观察模式是否成功。并且可能由于电脑环境 CPU GPU 老化或者其他原因，最优超参也是会不
断变化，每隔一段时间需要重新调节超参。

凭经验的过程通俗的来说就是不断尝试直到找到合适的数值。
empirical process is maybe a fancy way of saying you just have to try a lot of things and see what works.

深度学习用于计算机视觉、语音、自然语言处理、广告投放、搜索、数据分析等。深度学习应用到了很多结构化的数据分析中。


** 提升深度神经元网络：超参调节、正则化、最优化

深度学习中有很多的超参，我们不可能一开始就是知道这些超参的最优解。应用机器学习的过程是一个高度迭代的过程：在项目启动的时
候，我们有一个初步想法（对超参的一个设置），然后运行代码进行实验，根据结果去改变策略或者完善想法，从而不断找到更加优化的
网络。深度学习已经应用到了各个领域，经常有某个领域的专家投身到其他领域中去，然而不同领域对超参设置的直觉、经验通常并不适
合其他的领域。最佳的选择通常依赖于你的数据量、输入特征的数量、计算机的配置（GPU群、单GPU、CPU）。所以即使是专家也通常无
法开始就知道超参的准确值，深度学习是一个典型的迭代的过程，通过不断的验证来提高网络的性能。所以项目的进度直接依赖于每一个
迭代的时间，设置高质量的训练、验证、测试集可以提高迭代的效率。

*** Training - Development - Test Data Set

正确选择训练集、验证集[Hold-out cross validation]、测试集可以很大程度上帮助我们创建一个高效的神经网络。

在样本较少的机器学习时候，普遍认为最好的比例为 70/30 的训练集和交叉验证集，或者 60/20/20 的训练集、交叉验证集、测试集。
在深度学习中，一般都有海量的数据，此时验证集和测试集的比例会变得很小。因为验证集目的是验证不同算法的优劣，所以验证集只需
要拥有能够验证那个算法更好的个数的样本就可以。测试集的目的是评估分类器的性能，同样并不需要 20% 的数据去评估。并且可以没
有测试集，因为测试集是为了得到网络性能的无偏估计，当不需要网络的无偏估计的时候可以不需要测试集。

100万 ： 98/1/1, 数据量更大时：99.5/0.25/0.25, 99.5.0.4/0.1

训练集和测试集分布不同： *确保验证集和测试来自相同的分布。* 利用爬虫等从网络上获取训练图片，可能使得网络的训练集和测试集
分布不同，但是一定要让验证集和测试集的分布相同，这样可以让机器学习算法收敛的更快。

*** Bias and Variance

偏差和方差两个概念很容易学，但很难理解(Easy to learn but hard to master)。即使你认为已经学会了两者的基本概念，不过总是有
一些意想不到的新东西出现。

在深度学习中，不再需要权衡(trade-off)偏差和方差。因为现在有方法可以只较小偏差而对方差的影响很小，或者只减小方差而对偏差
的影响很小，不像原来那样减小其中一个势必增大另一个。

在二维时可以通过画图达到可视化的效果来观察偏差和方差；在高维空间中可以通过训练误差和验证误差两者来观察偏差和方差。

| 训练集误差 | 验证集误差 | 偏差-方差[贝叶斯误差接近 0%，训练样本和验证样本同分布] |
|------------+------------+--------------------------------------------------------|
|         1% |        11% | 高方差（过拟合）                                       |
|        15% |        16% | 高偏差（欠拟合）                                       |
|        15% |        30% | 高偏差和高方差                                         |
|       0.5% |         1% | 低偏差和低方差                                         |

同时高偏差和高方差的情况：在高维空间中，有些区域偏差高、有些区域方差高。

偏差比较高的时候，如果去寻找更多的训练样本来训练网络，通常帮助不大，且会浪费时间。所以一定要清楚系统现在是高偏差还是高方
差，从而使用更加精确的方法来改善系统。

调试系统的基本方法：
1. 首先查看系统是否是高偏差。根据人眼的识别率来近似估计贝叶斯误差；如果系统的偏差较大，可以通过训练更大的网络（增加网络
   的层数或者隐层节点的个数）、增长训练时间、改善系统的网络架构等方法来减小偏差，直到将偏差降低到一个合理的范围。
2. 然后依据偏差的大小查看系统的是否是高方差。如果系统是高偏差，可以通过使用更多的训练样本、正则化、不同的网络架构等方法
   来改善偏差。
3. 如果需要再进入第一步，直到训练出一个合理的系统。

训练一个正则化的更大的网络几乎没有任何负面影响，只是会增长训练时间，需要更大的训练样本。

*** 正则化

如果怀疑网络出现了过拟合，首先应该考虑正则化，当然使用更多的训练样本同样可以减小过拟合，但有时候可能不现实。

square Euclidean norm 欧几里德范数的平方

正则化的时候只考虑权重 w ，而不考虑 b ，是因为 w 包含了绝大多数参数，而 b 只有很少的参数，影响不大。当然如果需要同样可以
在正则化项中增加 b 。

\begin{align*}
J(W^{[1]}, b^{[1]}, \cdots , W^{[L]}, b^{[L]}) & = \frac{1}{m} \sum_{i=1}^m L({\hat{y}}^{(i)} - y^{(i)}) 
\color{red}{ + \frac{\lambda}{2m} \sum_{l=1}^{L} ||W^{[l]}||_F^2 } \\
dW^{[l]} & = dZ^{[l]} \cdot {A^{[l-1]}}^T \color{red}{ + \frac{\lambda}{m} W^{[l]} } \\
W^{[l]} & := W^{[l]} + \alpha dW^{[l]} \\
& = W^{[l]} - \alpha ( dZ^{[l]} \cdot {A^{[l-1]}}^T \color{red}{ + \frac{\lambda}{m} W^{[l]} } ) \\
& = (\color{green}{1 - \frac{\alpha \lambda}{m}}) W^{[l]} - \alpha ( dZ^{[l]} \cdot {A^{[l-1]}}^T )
\end{align*}

由于 \(1 - \frac{\alpha \lambda}{m} < 0\) ，L2 正则化也称为权重衰减(weight decay)。
L2 正则化使用较广泛。Frobenius norm

\[  ||W^{[l]}||_F^2 = \sum_{i=1}^{n_l} \sum_{j=1}^{n_{l-1}} w_{ij}^{[l]} \]

L1 正则化可以使权重变得稀疏，也就是会使权重中存在较多的 0 。吴恩达认为虽然有较多的权重参数为 0，但是对减少存储空间没有太
大的贡献。

lambda 是正则化参数，通过交叉验证来选择，从而使得训练误差和权重参数之和最小，来减小过拟合的风险。

lambda 是 Python 的一个保留关键字，编程时使用 lambd 来代替表示正则化参数。

*直观理解正则化可以减小方差：* 增加正则化项，假如正则化参数 labda 很大，那么将有很多的权重参数变得几乎为 0，从而消除或者
减小了中间网络层节点对结果的影响，从而使得网络变得简单。从而不容易产生过拟合。逐渐减小正则化参数，可以找到一个合适的值使
得网络偏差和方差都不是很大。

Dropout（随机失活）是一个非常有效的正则化方法。常用 inverted dropout，只在训练阶段使用 dropout，在测试阶段不使用 dropout。

#+BEGIN_SRC python
# 每次训练的时候 dropout 的网络节点不相同，都是随机的
# inverted dropout
keep_prob = 0.5
# 反向传播的时候仍然使用该矩阵
dropout3 = np.random.randn(a3.shape) < keep_prob
a3 = np.multiply(a3, dropout3)
a3 /= keep_prob
#+END_SRC

*直观理解 Dropout ：* Dropout 使得网络结构变得简单，从而减少了过拟合；由于会随机丢弃一些节点，所以一个神经元就不能够依赖
其某一个或者某几个固定的输入节点，而是会将权重分散开来到每一个输入节点，相当于 shrink 了权重，所以使得权重参数的 F 范数
变少，达到了类似 L2 正则化的效果。

可以在不同的网络层使用不同大小的 keep_prob ，在含有较多权重参数的网络层，使用较小的 keep_prob （如 0.5），从而预防该层网
络过拟合；在含有较少权重参数的网络层，使用较大的 keep_prob （如 0.7 、0.9），因为不用太担心该层网络会过拟合。输入层一般
不使用 Dropout ，即让 keep_prob 等于 1 ，或者很接近 1 的某个值。当然让不同的网络层有不同的 keep_prob 增加了超参的个数，
需要使用交叉验证来选择参数。

Dropout 使得代价函数 J 的定义变得不明确，因为每次都会随机丢弃一些节点。所以在最开始训练的时候可以先关掉 Dropout ，使网络
所有层的 keep_prob = 1 ，观察代价函数 J 是否会随着迭代次数的增加而减小，从而减小因为引入 Dropout 而导致的 bug 。然后再打
开 Dropout 开始训练网络。

记住：Dropout 是为了防止网络过拟合的一种正则化方法，除非确认网络会过拟合，否则不要使用。当然 Dropout 在图像中使用很频繁，
因为有太多的参数，以至于总是没有足够数量的样本，所以才会默认都使用 Dropout。

data argumentation: 通过水平翻转(flipping horizontally)、随机裁剪(random crops)[原图随意旋转放大后再裁剪]等方法来扩大数
据集。这样数据集会有冗余，虽然不如使用全新样本效果好，但是节省了寻找新样本的时间。注意：需要经过处理后的样本仍然保持基本
模样，如可以将一张猫的图片水平翻转，但是不要上下翻转，那样猫将上下颠倒（我怎么感觉也需要上下翻转，因为有时候很有可能看到
的就是一个上下颠倒的猫）。对于光学字符识别，可以通过任意的旋转和扭曲来扩张数据。

early stopping：通过不断的迭代，训练误差不不断减小，但是验证误差会在减小到一定值之后开始增加，early stopping 就是希望在
验证误差比较小的时候停止。另外由于权重初始化为很小的值，随着迭代次数的不断增加，权重变得越来越大，early stopping 在权重
不是很大的时候停下了，就类似与 L2 正则化的效果。缺点：early stopping 会同时调节损失函数和正则化两者，不符合正交化的规则，
可能使得两者调节的都不好。使用 L2 正则化则可以让网络的迭代次数尽可能多，而无需考虑过拟合，只是需要多次验证最优的正则化参
数。

*正则化输入：* 将输入样本的均值和方差归一化将有助于提高网络的训练速度。因为假如样本的不同特征的范围差别很大（特征 1 的范
围是 0-1 ，特征 2 的范围是 1-1000）将会让损失函数的形状类似与一个细长形状，contour 是细长的椭圆。必须使用很小的学习速率
来反复学习（否则将远离最优解），势必需要耗费很多时间。而将特征归一化处理之后，损失函数将是一个圆碗的形状，其 contour 是
圆形，可以快速收敛。样本归一化只有在样本的不同特征范围差别很大的时候才会生效，但使用不会有什么坏处，所以可以总是使用。样
本正则化共需要两步：均值转换成 0 ，方差转换成 1 。

1. 让 \(\mu = \frac{1}{m} \sum_{i=1}^m x^{(i)}\)
2. 使用 \(x^{(i)} - \mu\) 逐一替换 \(x^{(i)}\) ；这两步用于将均值变换成 0，若已知均值为 0 ，可跳过此步骤
3. 让 \(\sigma_j^2 = \frac{1}{m} \sum_i (x_j^{(i)})^2 \) ；逐元素求平方
4. 使用 \(x_j^{(i)} / \sigma_j\) 逐一替换 \(x_j^{(i)}\) ；将协方差变为单位阵，方差归一化使得不同的属性拥有相同的尺度。

*在测试集中仍然需要使用训练集的 \(\mu\) \(\sigma\) 参数，不可以让测试集去使用自己的参数*

*** vanishing / exploding gradient

梯度消失/爆炸：当网络的层数很深的时候，如果所有的权重都大于 1 ，那么最终节点的输出值将变得很大；如果所有权重都小于 1 ，
那么最终的输出值将变得很小。从而出现梯度爆炸或者消失的问题。可以通过合适的选择权重初始化的值来缓解这个问题，让所有节点的
输出值都在 1 的附近，从而不会很快的爆炸或者消失。同样是一个加速训练网络的方法。

#+BEGIN_SRC python
# hurd 论文公式，适用 ReLU 激活函数
Wl = np.random.randon(nl, npl) * np.sqrt(2 / npl)
# 可以将 2 视为一个超参来调节，但其优先级较低
#+END_SRC

*** Gradient check

使用梯度检查有利于查找代码中的 bug 。方法：将所有的权重参数 \(W^{[1]},b^{[1]},\cdots,W^{[L]},b^{[l]}\) 都变换成列向量，
然后串接成一个大向量 \(\theta\) ，其中每一个列向量记为 \(\theta_1,\theta_2,\cdots,\theta_{2L}\) 。同时将所有的梯度向量
\(dW^{[1]},db^{[1]},\cdots,dW^{[L]},db^{[l]}\) 转换成列向量并串接成一个向量 \(d\theta\) 。使用 for 循环变量大向量
\(\theta\) 的每一个小向量 \(\theta_i\) ，计算 \[ d\theta_{approx} [i] = \frac{J(\theta_1,\theta_2,\cdots,\theta_i +
\varepsilon, \cdots, \theta_{2L}) - J(\theta_1,\theta_2,\cdots,\theta_i - \varepsilon, \cdots,
\theta_{2L})}{2\varepsilon} \] 然后比较两个向量 \(d\theta_{approx},d\theta\) 的相似度 \[ \frac{||d\theta_{approx} -
d\theta||_2}{||d\theta_{approx}||_2 + ||d\theta||_2} \] 通常选取 \(\varepsilon = 10^{-7}\) ，查看两个向量的相似度如果也
在 \(10^{-7}\) 表明没有问题，若在 \(10^{-5}\) 则可能有问题，更大的话则肯定有问题。这里使用的是双边检查，相比于单边检查更
加精确。另外有几点需要注意：

+ 只在 debug 的时候使用双边检查。训练网络的时候不要使用，否则会减慢训练速度
+ 如果检查有问题，可以通过比较两个大向量的差别比较大的 i 来进一步定位问题的位置
+ 如果使用了正则化，记得在代价函数和梯度中都有相应的增加项
+ 不使用 Dropout
+ 在网络训练过一段时候后，再次检查一下；可能网络只在权重比较小的时候是正确的

\begin{gather*}
f'(\theta) = \lim_{\varepsilon \to 0} \frac{f(\theta + \varepsilon) - f(\theta - \varepsilon)}{2\varepsilon}. \quad 
error \ O(\varepsilon^2) \\
f'(\theta) = \lim_{\varepsilon \to 0} \frac{f(\theta + \varepsilon) - f(\theta)}{\varepsilon}. \quad 
error \ O(\varepsilon) \\
\end{gather*}

O(n): on the Order of 。表示常数乘以括号中的项

*** mini-batch gradient descent

当训练数据即非常大的时候（比如有 500 万个样本），使用批量梯度下降法将非常的耗时，因为必须要计算所有的样本后才可以调节参
数。因此使用 mini-batch 梯度下降法结合了随机梯度下降法和批量梯度下降法两者的优点：可以使用向量话计算同时避免必须计算完所
有样本后才能更新参数。

将样本特征和标记都分成许多等个数的小段，记为 \(X^{\{t\}}, Y^{\{t\}}\) 。计算过程同批量梯度下降法类似，将所有训练样本迭代
一次称为一个 epoch 。

mini-batch size 是一个很重的超参，使用时需要快速选择。使用较大的是 64-512 之间的某个 2 的次方数。并且确保 mini-batch
size fit in 你的 CPU / GPU 的内存。

*** Momentum

通常选取 momentum 参数 \(\beta = 0.9\) ，这是一个比较鲁棒的值。

\begin{align*}
V_{dW} & = \beta V_{dW} + (1 - \beta)dW \\
V_{db} & = \beta V_{db} + (1 - \beta)db \\

W & = W - \alpha V_{dW} \\
b & = b - \alpha V_{db}
\end{align*}

#+BEGIN_SRC python
VdW = np.zeros(dW.shape)
Vdb = np.zeros(db.shape)
# 第 t 次迭代，计算 mini-batch 的 dW db
VdW = beta * VdW + (1 - beta)dW
Vdb = beta * Vdb + (1 - beta)db

W = W - alpha * VdW
b = b - alpha * Vdb
#+END_SRC

计算得到本次的导数值之后，使用指数加权移动平均来估计过去 10 次迭代的平均值，然后使用平均后的权重值来更新权重。这样将使得
迭代左右来回摆动得到抑制（细长型的代价函数，每次迭代都会左右摆动，通过计算过去 10 次的平均值，正负得到抵消，左右摆动将会
被消除很多，相当于给其增加了摩擦力，估计也是称为 momentum 的原因），而使用向最优解移动的方向则不会被抑制。由于仅需经过
10 次迭代之后就可以消除因为初始化为 0 带来的偏差，通常不需要偏差修正。


**** Exponentially Weighted Moving Averages

\[ V_t = \beta V_{t-1} + (1 - \beta) \theta_t \] 指数加权移动平均，大约相当于求取了 \(\frac{1}{1-\beta}\) 个数的平均值
\( (1-\varepsilon)^{\frac{1}{\varepsilon}} = \frac{1}{\varepsilon}\) 。当 \(\beta\) 较小的时候（比如等于 0.5），平均的数
量较小，会对当前值有快速的响应，但也会有较大的震荡；当 \(\beta\) 较大的时候（比如等于 0.99），求取了太多数量的平均值，导
致对当前数值不敏感，最终的曲线会有延后。使用时作为超参来调节。

实际使用时只需要先将 V 初始化成 0，然后有新的值时使用公式 \(V := \beta V + (1-\beta) \theta_i\) 更新 V 即可。这样只需要
占用一个内存，也很高效；虽然计算并不精确，如果时刻记录过去 50 个的值，然后求和在求平均计算更精确，但比较繁琐，且耗内存。
Bias correction，由于将 V 初始化成 0，导致最初的估计会存在偏差。可以在求得 V 之后再除以一个修正变量
\(\frac{V}{1-\beta^t}\) 来代替 \(V\) ，就可以修正因初始值估计不准确而导致的偏差。


*** RMSprop

root mean square prop ：让每个权重参数都除以自己的过去 \(\frac{1}{1-\beta_2}\) 个绝对值的平均，来消除较大的变化

\begin{align*}
S_{dW} & = \beta_2 S_{dW} + (1 - \beta_2) dW^2 \\
S_{db} & = \beta_2 S_{db} + (1 - \beta_2) db^2 \\
W & := W - \alpha \frac{dW}{\sqrt{S_{dW} + \varepsilon}} \\
b & := b - \alpha \frac{db}{\sqrt{S_{db} + \varepsilon}}
\end{align*}

#+BEGIN_SRC python
# 第 t 次迭代，计算出 dW db 后
SdW = beta2*Sdw + (1 - beta2)dW**2 # 逐元素求平凡
Sdb = beta2*Sdb + (1 - beta2)db**2

W = W - alpha * dW / np.sqrt(SdW + epsilon) # epsilon 是一个很小的值，防止除以 0
b = b - alpha * db / np.sqrt(Sdb + epsilon) # epsilon 可取 10^(-8)
#+END_SRC


*** Adam

Adaptive momentum estimation 结合了 Momentum 和 RMSProp 两个算法，需要偏差修正。

\begin{align*}
& V_{dW} = 0 \\
& V_{db} = 0 \\
& S_{dW} = 0 \\
& S_{db} = 0 \\
& \text{mini-batch gradient descent to compute dW and db on iter t} \\
& V_{dW} = \beta_1 V_{dW} + (1-\beta_1)dW \\
& V_{db} = \beta_1 V_{db} + (1-\beta_1)db \\
& S_{dW} = \beta_2 S_{dW} + (1-\beta_2)dW^2 \\
& S_{db} = \beta_2 S_{db} + (1-\beta_2)db^2 \\
& V_{dW}^{corrected} = \frac{V_{dW}}{1-\beta_1^t} \\
& V_{db}^{corrected} = \frac{V_{db}}{1-\beta_1^t} \\
& S_{dW}^{corrected} = \frac{S_{dW}}{1-\beta_2^t} \\
& S_{db}^{corrected} = \frac{S_{db}}{1-\beta_2^t} \\
& W := W - \alpha \frac{V_{dW}^{corrected}}{\sqrt{S_{dW} + \varepsilon}} \\
& b := b - \alpha \frac{V_{db}^{corrected}}{\sqrt{S_{db} + \varepsilon}} \\
\end{align*}

超参选择：
+ \(\alpha\) 需要调节
+ \(\beta1 = 0.9\) 
+ \(\beta2 = 0.999\)
+ \(\varepsilon = 10^{-8}\)




*** Learning Rate Decay

由于不断的迭代，参数将不断趋向于最优解，但由于使用了 moni-batch ，所以算法最终无法收敛到最优解，这时需要不断减小学习速率，
使得求得的参数可以在最优解的较小的周围徘徊。

\begin{align*}
& \alpha = \frac{1}{1 + decay-rate * epoch-num} \alpha_0. \quad \text{decay-rate haper-paramter} \\
& \alpha = 0.95^{epoch-num} \alpha_0. \quad \text{expontrally decay} \\
& \alpha = \frac{k}{\sqrt{epoch-num}} \ or \ \alpha = \frac{k}{\sqrt{t}} \\
& \text{Discrete decay} \\
& \text{manual decay}
\end{align*}

*** 局部最优解

当参数非常多的时候，不同于以往的对三维空间理解，很难碰到局部最优解（所有的参数变化都导致损失函数增大或减小），很有可能只
是鞍点(saddle points)。在鞍点会有一个较长的停滞期(plateaus)，这个时候梯度变化很小，几乎为 0，导致会有长时间在该段停留。
而 Adam 最优化方法有助于加速停滞期的迭代？？为什么？？


超参的重要级别：学习速率 \(\alpha\) ；mini-batch size 、 隐层节点个数 hidden units 、Momentum 参数 \(\beta\) ；网络的层
数 layers 、学习衰减率 learnning rate decay ；Adam 算法参数。

寻找超参时，在某个范围内随机采样(random value) ，而不是使用将区域等分的网格值(grid) 。在参数维的空间内进行随机采样（其实
是在每个参数的范围内单独随机采样，然后组合起来），这样可能有更多的数值被使用来训练（使用 grid 的时候会多次使用重复的参数
值），更容易找到最优参数，会提高搜索效率。；使用由粗到细的搜索方法(coarse to fine) ，即先在比较大的范围内所有超参的最优
解，找到一些比较好的区域后，在该区域内重点搜索，采样更多的样本，从而更精确的找到超参的最优值。

*** 超参调试
选择合适的尺度有利于加快超参的搜索速度。有些超参，比如网络的层数、隐层节点的个数、输入特征的维数等都可以使用 uniform 采
样；但是项学习速率 \(\alpha\) 和 Momentum 参数 \(\beta\) 使用 uniform 采样就不太合理，比如学习速率范围选择成 0.0001-0.1
范围，如果在该区间 uniform 采样，那么将有 90% 的概率落在 0.001-0.1 之间，显然不太合理。此时可以考虑使用对数坐标，将取值
范围表示成 10 的多少次方到 10 的多少次方，先在两个次方的范围内使用 uniform 采样，再将 10 为底，采样得到的值为指数，并将
该值作为超参使用。Momentum 参数选取范围 0.9-0.999 ，同样不应该使用 uniform 采样，此时希望调节的是想要平均的个数，因此应
该让该个数得到 uniform 采样。

#+BEGIN_SRC python
# r ~ [-4,-1]
r = np.random.randn() * (-3) - 1
alpha = 10^r

r = np.random.randn() *(-2) -1
beta = 1 - 10^r
#+END_SRC

由于更换了服务器或者 GPU 等原因，需要 Re-test hyperparameters occasionally ，每几个月都要重新测试调节一次。当计算资源充
足的时候，可以同时使用不同的参数训练多个网络，从而可以快速找到最优的超参；当没有足够的计算资源，没有只可以训练一个网络的
额时候，需要每天不断的观察网络训练的结果，依据误差曲线走势等来不断调节超参。

现在深度学习应用的已经相当广泛，不同领域的一些想法可以应用到其他领域。

*** Batch Normalization

类似于将样本进行归一化有助于加快网络的训练，batch norm 的目的是让网络的每一层输出都进行归一化，使得每一层网络的输出值都
是归一化后的值，更加有利于后面层网络参数的学习，从而进一步加速网络的训练。另外并不希望所有网络层的输出都是 0 均值、方差
为 1 ，所以 batch norm 为每个节点增加了均值和方差两个参数来调节归一化结果的分布，这两个参数有网络学习得到。又由于增加了
均值这个参数使得节点原来的偏移参数 b 不再有意义，可以去掉。

可以有两种不同的使用方法：在求取激活函数之前进行归一化，然后再利用激活函数得到该层网络的输出；也可以先计算激活函数的输出，
然后再进行归一化。第一种方法较为常用。为什么？

\begin{align*}
\mu = \frac{1}{m} \sum_i Z^{[l](i)} \\
\sigma^2 = \frac{1}{m} \sum_i (Z^{[l](i)} - \mu)^2 \\
Z_{norm}^{[l](i)} = \frac{Z^{[l](i)} - \mu}{\sqrt{\sigma^2+\varepsilon}} \\
{\widetilde{Z}}^{[l](i)} = \gamma Z_{norm}^{[l](i)} + \beta
\end{align*}

使用 mini-batch 前向传播的时候在计算激活函数之前先使用 batch norm ，然后计算激活函数，继续传播；反向传播时使用和求取权重
参数 W 一样的方法来求取均值和方差参数 \(d\gamma, \ d\beta\) 。

batch norm 使得网络每一层的输出值都得到归一化，归一化到某个分布。这将减小前面层网络参数的变化对后面层权重的影响，因为不
论前面层如何变化，都始终服从某个固定的分布，当前面层的输入变化时，其输出变化不会很大，所以后面的网络层的输入不会变化很大，
从而前面输入的变化对后面层网络权重参数的训练的影响减小，类似 *达到了让每层网络参数独立训练的效果* 。另外 batch norm 还有
一点正则化的效果，由于使用 mini-batch 只是所有训练样本的一小部分，所以其均值和方法都含有一定的噪声，每次使用 mini-batch
的样本去训练网络，并用含有噪声的均值和方法去归一化每一层的输出，就类似于 Dropout 随机丢弃网络中神经元节点一样，达到了轻
微的正则化的效果。


Sometimes it has some extra intended or unintended effect on your learning algorothm.

*** softmax


*** Tensorflow


** 深度学习策略

Deeplearning strategy ：诊断系统的瓶颈和 debug 的能力。

虽然很多深度学习研究人员说，他们只是将数据输入系统，然后系统自己去学习相应的知识，中间没有人为干预。但是搭建一个系统时，
是需要很多很多人为干预的，需要人类的经验来搭建一个可以自动学习的系统。

*** Orthogonalization

老式电视机设计者花费很多时间来设计，使得每个旋钮都有明确的功能，每个旋钮只能调节一个功能选项，每个旋钮互相不影响，从而单
独调节需要的选项，使得调节更加容易。达到了相互 *正交化* 的功能。

机器学习假设链：

1. fit training set well on cost function
   + 如果系统在训练集上表现不好：训练更大的网络（模型不够复杂来拟合映射函数）、增加训练时间、更好的优化算法（Adam 等）、
     调节超参或者更改网络架构
2. fit development set well on cost function
   + 算法在在训练集上表现良好，但在验证集上表现较差：正则化、更大的训练集（用更多的样本学得更多的知识，更好的泛化到验证
     集）、调节超参或者更改网络的架构
3. fit test set well on cost function
   + 在训练集和验证集上表现良好，但在测试集上表现较差：更大的验证集（此时可能对验证集过拟合了）
4. perform well in realWord
   + 算法在训练集、验证集、和测试集上表现都可以，但最终使用上表现较差：改变验证集或代价函数（在测试集上表现良好时，却并
     没有在真实使用时表现良好，说明要么验证集和测试集的分布不合理，要么代价函数指标不对 is not measuring the right thing）

*** Single number evaluation metic

单一评价指标：集可以使用 \(F_1 = \frac{2}{1/P + 1/R}\) (Harmanic mean)来评估指示算法的性能。这样当有很多的识别器，不同的识别器又有很多
的性能指标时，可以快速的知道哪个分类器的性能更优。

准确率和召回率需要权衡
+ precision: the examples that your classifier recognize as cats，what percentage actually are cats？正确率表明，如果识
  别器说这是一只猫，那么有 95% 的可能性表明这是一只猫。
+ recall: of all the images that really are cats，what percentage were correctly recognized by your classifier? 召回率即
  实际上是猫的图片中，有多少被分类器识别出来。

但有时候很难将很多要求的指标综合到一个单一的实数上，此时可以采取的策略是选择一个需要最优化的指标 optimizing metic ，让其
越小越好；其他的指标只要满足一定的阈值就好 satisficing metic （如运行时间小于 100ms ，24 小时内误唤醒次数小于 1），这些
指标只要达到要求的范围便不在乎有多好（运行时间 1ms 或者 99ms 都不关心），但一定要满足这些指标的阈值。

*** Train-development-test set

训练接、验证集、测试集的选取对训练迭代的效率有很大的影响。设定 development set 和 evaluation metric 就表明设定了需要瞄准
的目标靶心，设定了靶心后，不断的调节优化算法，使得算法能够逐渐靠近靶心。如果验证集和测试集输入不同的分布，相当于在测试时
更换了靶心目标，准确率肯定无法保证。

指导原则：选择的验证集和测试集一定能够反应你最终希望使用的场景。验证集和测试集从样本集中随机选取。

验证集和测试集并不再需要像机器学习中那样继续使用 20% 的样本（在样本数量比较小的时候可以）。当用于大量的样本的时候，可能
只需要分别有 10000 或者 100000 个样本来作为验证集和测试集即可，而这个比例将远远小于 20% 。当确信验证集足够大， *算法不会
在验证集上过拟合的时候，* 可以省略测试集（但强烈不建议这么做）。Set your test set to be big enough to give high
confidence in overall performance of your system. And the development set has to be big enough to evaluate different
ideas.

*当评价指标无法区分哪一个算法更好的时候，需要更改评价指标* （或者验证集和测试集）。因为评价指标的作用就是评价算法的优劣。
例如要训练一个猫脸识别器，最终两个分类器比另一个分类器的识别率高，但是该分类器会将一些色情图片误分称猫，这是绝对不能容忍
的。此时需要在代价函数中增大色情图片误分的权重。或者使用验证集和测试集都是高清的图片，但最终用户使用的都是一些低分辨率的
图像，使得一个算法 A 在验证集的测试集上表现比另一个算法 B 好，但是在用户使用时却没有算法 B 表现好，此时需要修正验证集和
测试集。

即使最初无法定义一个完美的评价指标或者验证集和测试集，先使用其进行快速迭代，等发现问题再去修改；但不建议在没有评价指标和
验证集和测试集是长时间训练，那样会减缓进度。同时将定义评价指标和优化指标看成是相互正交的，两者可以分别单独调节。

如果只有少量的最终使用的场景样本，而有大量其他从网络上下载或者花钱购买的与实际应用分布不相同分布的样本：绝对不可以将所有
的样本混合，然后从中按比例随机选择训练集以及验证集测试集，这样会让验证集测试集中含有太多的不符合最终场景的样本，相当于放
错了靶心。 *验证集和测试集必须全部使用最终使用场景样本，* 因为这两者是为了设定算法的靶心；如果有剩余可以放入训练样本中。
当然缺点是这会让训练接和验证集测试集的分布不同，从会有数据不匹配误差。

此时应该在训练样本中保留一部分样本作为训练-验证集( *train-development set* )，这一部分样本和训练集的样本分布相同，但不用
于训练模型，而用于估计模型在训练集上的泛化误差。这样有助于估计模型在验证集测试集上增大的误差，是由于模型的泛化能力较差，
还是由于训练集和验证集测试集因为分布不同而导致的数据不匹配(data mismatch)所引起的。

| human error(train set)  |             0% |                                               0% |                   0% |                                     0% |                |
|                         |                |                                                  |                      |                                        | available bias |
| train error             |             1% |                                               1% |                  10% |                                    10% |                |
|                         |                |                                                  |                      |                                        | variance       |
| train-development error |             9% |                                             1.5% |                  11% |                                    11% |                |
|                         |                |                                                  |                      |                                        | data mismatch  |
| development error       |            10% |                                              10% |                  12% |                                    20% |                |
| test error              |            10% |                                              15% |                  12% |                                    20% |                |
|                         | large variance | data mismatch and overfitting on development set | large available bias | large available bias and data mismatch |                |

当然如果验证集测试集比较简单，则可能出现在验证集测试集上的误差小于在 train-development 上的误差。

*处理 data mismatch：* 人工分析训练集与验证集之间的差异（只分析训练集与验证集的差异，不分析训练集与测试集的差异，因为那
样可能会导致在测试集上过拟合），比如验证集中大多数图片都比较模糊、有较大的噪音、包含较多的街道数字、人脸有较大的旋转等等；
找到不同的特征后，尝试将训练集变得更像验证集（通过认为合成噪声）或者收集更多同验证集分布相同的样本来训练算法。

Data mismatch 并没有系统的解决办法，但上述方法通常可以对问题的解决有很大的帮助。

~Using artificial data synthesis, be cautious and bear in mind whether or not you might be accidentally simulating data
from a tiny subset of the space of all possible examples.~ 比如将 1 小时的噪声加到 10000 小时的训练样本中，或者从游戏中
截图很多很多的汽车的图片（实际上游戏中可能只有 20 种车型），虽然在人类看来这些合成的声音或者图片都相当的好，可是这些只是
需要处理的问题集中很小很小的一部分，算法很有可能只会对这 1 小时的噪声或者 20 中车型过拟合。

吴恩达说通过人工合成的方法使得已经很好的语音识别系统又有了很大的提高。所以人工合成的方法还是可以使用的。


*** 最优分类器


贝叶斯最优误差： 在人类擅长的领域（如图像识别、语音识别），人类的表现已经很好了，很接近贝叶斯最优误差，所以经常使用人类
的表现来近似估计贝叶斯误差。

算法达到人类表现后很难继续优化的原因： 当算法超越人类的表现的时候，提升空间已经不大了；并且当算法表现性能不如人类的时候，
可以通过使用更对人为标记的样本、人工错误分析、更容易分析 bias/variance，但是当算法的性能高于人类的时候，这些方法就很难实
施，所以导致缺少调试方法来使得算法的性能进一步提升（用另一个算法来提升该算法？？？）。

原来一直默认贝叶斯最优误差约为 0，但是有些问题并不是（比如在噪音特别大的环境中辨别一句话）。此时应该清晰的了解贝叶斯最优
误差的大致范围，才能指导训练算法。当模型的训练误差和验证误差相同时，由于贝叶斯误差的不同，需要采取不同的方法来调节算法。
而在人类非常擅长的领域，使用人类的表现来近似估计贝叶斯误差。由于贝叶斯误差是理论上限，所以不管是一个特别擅长的人的表现还
是一个团队共同决定后的表现，总是取误差最小的那个值最为贝叶斯误差的估计。当算法很接近人类的表现的时候，如果继续减小训练集
的误差很可能只会过拟合。

吴恩达将算法的训练误差与人类的表现误差之差称为可避免误差(avoidable bias)。
| 人类的表现   |     1% |   7.5% |
| 模型训练误差 |     8% |     8% |
| 验证误差     |    10% |    10% |
| 结论         | 高偏差 | 高方差 |

当一个算法在训练集上的误差为 0.3% ，验证集上的误差为 0.4% ，而一个团队的决定表现的误差为 0.5% 。此时就很难知道贝叶斯误差
是多少（可能是 0.1% 也肯能是 0.4% ），算法是过拟合了还是仍有提升空间将难以使用原来的方法进行判断。

在线广告投放、产品推荐、逻辑推理、贷款评估等方面，计算机早已经远远超越人类；同时在某些特定的语音识别、图像识别领域，机器
也有一些超越了人类的表现。

监督学习的两个基础：算法在训练集上表现良好，有较小的可避免误差；在验证集上表现良好，模型泛化到没有经过训练的验证集测试集
时误差不会增加很多。

*** 误差分析

在验证集或者测试集找到一些分类错误的样本（100 个，或者更多），统计 (false positive 和 false negative) 不同类型错误的个数，
如果在统计的过程中发现了错误分类样本新的共性，可以随时添加新的一类重新统计，最终得到不同错误类型占总错误的百分比，从而帮
助我们找到系统最需要解决的问题，并大致了解各个改进后的结构对系统性能的提升空间。

|   图片 | 狗 | 大型猫科 | 模糊 | 滤镜 | comments |
|--------+----+----------+------+------+----------|
|      1 |  1 |        0 |    1 |    0 | 柯基     |
|      2 |  0 |        0 |    1 |    1 |          |
|      3 |  0 |        1 |    0 |    0 | 豹子     |
|      4 |  0 |        0 |    1 |    0 | 非常模糊 |
|    ... |    |          |      |      |          |
| 百分比 | 8% |      43% |  61% |  12% |          |

*样本标记错误：* 深度学习算法对随机错误非常鲁棒。所以如果训练样本中有些许样本由于某些随机因素而标记错误，并不会对算法产
生影响；但是如果是系统误差，即将所有白色的小狗都标记成了猫，那么算法将会受到影响。如果在验证集和测试集中有标记错误的样本，
则需要评估这些标记错误的样本对最终正确率的影响，如果标记错误的样本占最终错误率已经影响到了对不同算法优劣的评估，则需要修
正这些标记错误的样本，如果标记错误的样本只是占很小的比例，那么先处理其他更重要的事情，暂不修改标记。同时要 *注意* ，如果
要修正标记错误的样本，必须对验证集和测试集做同样的操作，以确保两者的分布相同；并且应该同时处理那些分类正确和分类错误的样
本，否则会引入偏差（不过实际上，很少有人这么做，一般只修正分类错误的样本，因为分类正确的样本数量太大）；修正标记后，训练
集和验证集测试集的分布会稍微有些不同。


*** Build first system quickly

语音识别系统： 可能有 50 个不同的改进方向，每一个都可以改善系统。 *But the challenge is how do you pick which of those
to focus on.*

+ 嘈杂的环境： cafe noise、car noise
+ 口音
+ 远场语音识别
+ 儿童语言
+ 口吃

~Guideline： Build your first system quickly and dirty, then iterate.~

1. 设置验证集、测试集和评价指标。就是先设定目标靶心
2. 快速搭建一个原始系统。原始系统可能很差劲，不过无所谓。当然如果有一些可能参考的文献，那么可以借鉴
3. 使用 bias/variance 分析、误差分析等方法来分析下一步的方向。

吴恩达说有些系统搭建的太简单，但更多的是很多团队搭建了一些过于复杂的系统。所以应该从简单开始，然后逐步去分析处理需要解决
的问题，慢慢让系统变复杂，等达到要求就可以终止。当然这些处理流程都是在解决实际问题，严重不适合去发明一个新的算法。


*** Transfer learning

*迁移学习：* 如果任务 A 和任务 B 使用拥有的输入，且任务 A 有远多于任务 B 的样本，那么任务 A 学得的 low level features 将
有助于任务 B的训练。可以根据任务 B 的样本数量，将任务 A 的最后一层或者几层权重使用随机初始化的方法来重新赋值（也可以更改
后面基层网络的结构，如增加新的网络层或者删除某些节点），然后使用任务 B 的样本只训练最后几个重新初始化权重的网络层。

如果有较充足的样本，可以先使用其他相似模型对权重进行初始化，也称为预训练( *pre-training* ) ；然后再使用样本对网络进行参
数进行训练，只是不再采用随机初始化的方法来初始化权重，而是使用前面模型的权重来初始化模型，这样的训练称为调优(
*fine-tunning* ) 。


*** Mutilate task learning

多任务学习在计算机视觉中运用较多，比如同时去识别图像中很多不同的物体。多个不同的任务会共享 low level features 。此时的代
价函是所有不同任务的代价函数的总和。并且当一些图片中并没有标记某些类别的物体是否存在的情况下，仍然可以使用多任务学习来训
练。

\begin{equation*}
J = \frac{1}{m} \sum_{i=1}^m \sum_{j=1}^c \mathcal{L} (\hat{y}_i^{(i)}, y_j^{(i)})
\end{equation*}

只要网络足够大，多任务学习的效果通常优于多个单任务网络的效果。一般用于需要同时处理几个相近的任务，且各个任务的样本数量相
差不太大，通过组合这些样本来训练一个更大的网络。


*** End-to-end learnning

端到端的学习：直接从输入中间经过一个网络然后得到输出。当有非常多的样本的时候，使用端到端的学习效果会很好；但是如果样本量
比较小的时候，传统的人工设计 pipeline 的方法往往效果更好。

比如人脸识别系统，如果直接将一张包含人脸的图像作为输入，希望得到这个人的身份信息，往往效果不好，同时也没有很多这样的样本。
实际中一般分成两步，先检查出人脸的位置，然后只将包含人脸的方框用于网络的输入。这样每一步的任务都比较容易实现。（训练人脸
识别时，使用的人脸库，需要先将这些人脸进行裁剪，然后再送入网络进行训练）

优点：
+ Let the data speak ：无论从输入到输出的映射函数是什么，让网络自己去学习数据中的信息，而不引入任何人为观点
+ Less hand-designing of components needed ：简化了设计流程

缺点：
+ Need large amount of data
+ Excludes potentially useful hand-designed components ：无法将人类的经验注入算法

只在样本的数量足以训练从输入 x 到输出 y 的映射的时候才使用端到端的学习。并且要 carefully choose what types of x to y
mappings you want to learn depending on what task you can get data for. 可以让端到端的学习只是系统的一个组件，或者整个系
统就是一个端到端的系统。但不应该一味的不切实际的追求端到端。


** 卷积神经网络


** 自然语言处理


