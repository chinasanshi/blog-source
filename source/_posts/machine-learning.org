#+TITLE:       Machine Learning
#+AUTHOR:      Kyle Three Stones
#+DATE:        <2018-06-22 Fri 07:19>
#+EMAIL:       kyleemail@163.com
#+OPTIONS:     H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t f:t tex:t
#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler
#+STARTUP: latexpreview
#+TAGS:        机器学习, 
#+CATEGORIES:  机器学习

* ML
*机器学习* machine learning: Field of study that gives computers the ability to learn without being explicitly program.

机器学习并不是仅仅是若干算法的堆积，学会“十大算法”，熟练掌握具体算法算法的推导与编程实现，并不能让所有问题迎刃而解，因为
现实世界的问题千变万化。而应该像张无忌那样，忘记张三丰传授的太极剑法的具体招式，而只记住一些规则和套路，从而根据敌人的招
式去不断变化自己的招式，达到以不变应万变的效果。或者说用 Andrew Ng 的话，要成为一个 master carpenter （顶级木匠），可以
灵活使用工具来制造桌椅，只有手艺差的木匠才会抱怨工具不合适。因此必须把握算法背后的思想脉络，针对具体的任务特点，对现有套
路进行改造融通；要记住算法是 *死* 的，思想才是 *活* 的。

数据库提供数据管理技术，机器学习提供数据分析技术。

** Supervised Learning
监督学习

*** Support Vector Machines - SVM
*SVM 的基本思想就是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。* 

先写算法的最终求解方法，步骤。认为此时已经知晓所有知识。

**** 算法步骤
1. 构造含约束的最优化问题；根据 KKT 条件求得分离超平面的表达式
2. 求得相应的对偶问题
3. 利用 SMO 算法高效求解对偶问题，得到分离超平面的参数值
4. 依据分离超平面来处理新样本

再写一些术语的解释

**** 算法演进过程：

\begin{align}
max_{w, b} \quad & \gamma \\
s.t. \quad & y^{(i)} \left( \frac{w}{||w||} \cdot x^{(i)} + \frac{b}{||w||} \right) 
\geq \gamma, \quad i=1,2,\ldots,m
\end{align}

\begin{align}
max_{w, b} \quad & \frac{\hat{\gamma}}{||w||} \\
s.t. \quad & y^{(i)} \left( w \cdot x^{(i)} + b \right) \geq \hat{\gamma}, \quad i=1,2,\ldots,m
\end{align}

\begin{align}
min_{w, b} \quad & \frac{1}{2}||w||^2 \\
s.t. \quad & y^{(i)} \left( w \cdot x^{(i)} + b \right) \geq 1, \quad i=1,2,\ldots,m
\end{align}

\begin{align}
min_{w, b, \color{red}{\xi_i}} \quad & \frac{1}{2}||w||^2 + C\sum_{i=1}^m \xi_i \\
s.t. \quad & y^{(i)} \left( w \cdot x^{(i)} + b \right) \geq 1 - \xi_i, \quad i=1,2,\ldots,m \\
& \xi_i \geq 0, \quad i=1,2,\ldots,m
\end{align}

\begin{align}
max_{\alpha} \quad & W(\alpha) = \sum_{i=1}^m \alpha_i - 
\frac{1}{2} \sum_{i,j=1}^m y^{(i)}y^{(j)} \alpha_i\alpha_j \left \langle x^{(i)},x^{(j)} \right \rangle \\
s.t. \quad & 0 \leq \alpha_i \leq C, \quad i = 1,2,\ldots,m \\
& \sum_{i=1}^m \alpha_i y^{(i)} = 0
\end{align}

\begin{align}
max_{\alpha} \quad & W(\alpha) = \sum_{i=1}^m \alpha_i - 
\frac{1}{2} \sum_{i,j=1}^m y^{(i)}y^{(j)} \alpha_i\alpha_j K( x^{(i)},x^{(j)} ) \\
s.t. \quad & 0 \leq \alpha_i \leq C, \quad i = 1,2,\ldots,m \\
& \sum_{i=1}^m \alpha_i y^{(i)} = 0
\end{align}

\begin{align}
w^* & = \sum_{i=1}^m \alpha_i^* y^{(i)} x^{(i)} \\
b^* & = y^{(i)} - \sum_{i=1}^m \alpha_i^* y^{(i)} K(x^{(i)}, x^{(j)}) \\
f(x) & = sign \left( \sum_{i=1}^m \alpha_i^* y^{(i)} K(x \cdot x^{(i)}) + b^* \right)
\end{align}

1. 因为 SVM 学习算法的目标是最大化几何间隔\(\gamma\)，所以构建相应的模型，其目标函数表示为最大化几何间隔，同时约束每个训
   练样本距离分离超平面的距离大于该几何间隔。
2. 由于最终需要求解的是分离超平面的权重，所以需要利用几何间隔与函数间隔的关系，让目标函数中显示出现分离超平面的权重；即
   将目标函数和约束中的几何间隔统一改为函数间隔 \(\hat{\gamma}\)。
3. 函数间隔的取值并不影响上述最优化问题的解（当分离超平面的权重成比例变化时，函数间隔也呈现相应比例的变化），即函数间隔
   成比例变化时对不等式约束没有影响（相当于不等式的两边同时乘以该变化系数），对目标函数的优化也没有影响（目标函数的分子
   和分母同时乘以该变化系数）。为了简化模型表达式，取函数间隔为 *1* 。
4. 此时目标函数的分子为 1 ，分母为分离超平面的权重，且为求最大值。由于权重处于分母时，不利于求解，此时只需要最小化目标函
   数的分母即可。同时将权重转化为二次。此时的约束最优化问题与原问题是等价的，这是一个凸二次规划问题（convex quadratic
   programming）。Andrew Ng 讲解上述的变化都是在将非凸优化问题转化成凸优化问题。
5. 由于存在线性不可分以及 outliers 让分离超平面变差的可能。使函数间隔不再始终大于1，将函数间隔减去一个松弛变量，即函数间
   隔大于\(1-\xi_i\)。由于不再要求函数间隔始终大于1，所以可以找打一个分离超平面来分割不同的类别。但同时也不希望松弛变量
   太大，所以在目标函数中增加相应的正则化项（这里使用的是\(\ell_1\) regularization）。同时使用C来调节权重与松弛变量在目
   标含住中的比例关系。
6. 由于该凸二次规划问题求解时间复杂度较高，所以转而去求解相应的对偶问题。使用对偶问题可以高效求解，同时可以使用核函数。
7. 如果可以将特征都转换成內积的表示形式，就可以使用核函数。转换成內积形式以后，将表达式中的\(x\)转换成\(\phi(x)\) 就表示
   使用了核函数。而且并不需要知道\(\phi(x)\)的具体表达式，只需要代入\(\phi(x)^T \phi(z)\)乘积的结果，即选取的核函数的表
   达式\(K(\phi(x),\phi(z))\)就可以，这样将大大简化计算。
8. 另外转换成对偶问题后，可以使用 SMO（sequential minimal optimization）算法来高效求解参数\(\alpha_1,\ldots,\alpha_m\)

**** 术语解释
***** 原问题 - 对偶问题
虽然有很多的最优化算法可以求解该凸二次规划问题，但是当训练样本容量很大时，这些算法往往变得非常低效。而当参数满足
Karush-Kuhn-Tucker (KKT) 条件时，原问题和对偶问题的解相同；并且将原问题转换成对偶问题后，可以使用 SMO 算法高效求解，所以
才提出了原问题(primal program)及对偶问题(dual problem)。事实上这里使用的是拉格朗日对偶性(Lagrange duality)，原问题和对偶
问题的函数表达式都是拉格朗日函数(Lagrange function)。我们需要解决的问题一般都是含约束的最优化问题，而求解含约束的最优化
问题，一种有效的方法就是使用拉格朗日乘数法。使用拉格朗日乘数法首先构造拉格朗日函数，然后对拉格朗日函数参数的不同求解顺序
构成了原问题及对偶问题。

\begin{align}
min_{w} \quad & f(w) \\
s.t. \quad & g_i (w) \leq 0, \quad i=1,2,\ldots,k \\
& h_i (w) = 0, \quad i=1,2,\ldots,l
\end{align}

\begin{equation}
\mathcal{L}(w,\alpha,\beta) = f(w)+ \sum_{i=1}^k \alpha_i g_i(w) + \sum_{i=1}^l \beta_i h_i(w)
\end{equation}

\begin{align}
\theta_p(w) & = max_{\alpha,\beta:\alpha_i \geq 0} \ \mathcal{L}(w, \alpha, \beta) \\
min_w \theta_p(w) & = min_w max_{\alpha,\beta:\alpha_i \geq 0} \ L(w, \alpha, \beta) \\
p^* & = min_w \ \theta_p(w) 
\end{align}

\begin{align}
\theta_D(\alpha, \beta) & = min_w \ \mathcal{L}(w, \alpha, \beta) \\

max_{\alpha,\beta:\alpha_i \geq 0} \ \theta_D(\alpha, \beta) & = max_{\alpha,\beta:\alpha_i \geq 0}\ 
min_w \ \mathcal{L}(w, \alpha, \beta) \\

d^* & = max_{\alpha,\beta:\alpha_i \geq 0} \ \theta_D(\alpha, \beta)
\end{align}

\begin{equation}
d^* = max_{\alpha,\beta:\alpha_i \geq 0}\ min_w \ \mathcal{L}(w, \alpha, \beta) \leq
min_w max_{\alpha,\beta:\alpha_i \geq 0} \ \mathcal{L}(w, \alpha, \beta) = p^*
\end{equation}

将原始的问题转换成拉格朗日函数，其中\(\alpha_i\) 和 \(\beta_i\)都是拉格朗日乘子，而且不等式约束\(g_i(w)\leq0\)，要求其拉
格朗日乘子\(\alpha_i\geq0\)。此时只要不满足等式或者不等式约束，也就是存在一个或者多个\(i\)使得\(g_i(w) \ge 0\)或者
\(h_i(w)\neq0\)，那么求解\(\theta_p(w)\)的结果必然是无穷大；而当所有的\(i\)都满足约束时，\(\theta_p(w)=f(w)\)，此时两者
等价，再对\(\theta_p(w)\)参数\(w\)求最小，即为原始问题。也就是说，两者是等价的，相当于同一个问题。

\begin{align}
\theta_p(w) = \left\{ \begin{array}{} f(w) & 如果w满足原约束 \\
\infty & 否则 \end{array} \right.
\end{align}

而对偶问题就是调节一下求解的参数的顺序。原问题中先对参数\(\alpha,\beta\)求最大，然后对\(w\)求最小；对偶问题中先对参数
\(w\)求最小，然后再对参数\(\alpha,\beta\)求最大，也就是对调了 max 和 min 的求解顺序，仅此而已。

由于\(max min(\cdots) \leq min max(\cdots)\)，所以\(d^* \leq p^*\)。并且当\(w,\alpha,\beta\)满足 KKT 条件时，原问题的解和
对偶问题的解相同即\(p^*=d^*\)。反之也成立，即如果原问题和对偶问题的解相同，那么\(w,\alpha,\beta\)满足 KKT 条件。

\begin{align}
\frac{\partial}{\partial w_i} \mathcal{L}(w^*,\alpha^*,\beta^*) & = 0, \quad i=1,2,\ldots,n \\
\alpha_i^*g_i(w^*) & = 0, \quad i=1,2,\ldots,k \label{kkt:ducom} \\
g_i(w^*) & \leq 0, \quad i=1,2,\ldots,k \\
\alpha^* & \geq 0, \quad i=1,2,\ldots,k \\
h_i(w) & = 0, \quad i=1,2,\ldots,l \\
\end{align}

公式\(\eqref{kkt:ducom}\)称为 KKT 对偶互补条件（KKT dual complementary condition）；由此条件可知，若\(\alpha_i^* > 0\)，
则\(g_i(w^*) = 0\)。这个条件是说明 SVM 只有少数支撑向量的关键，同时也用于证明 SMO 算法收敛性。

具体到 SVM 算法，原问题的拉格朗日函数是

\begin{align}
\mathcal{L}(w,b,\xi,\alpha,\mu) = & \frac{1}{2}||w||^2 + C\sum_{i=1}^m\xi_i \notag \\
& - \sum_{i=1}^m\alpha_i[y^{(i)}(w \cdot x^{(i)} + b)-1 + \xi_i] - \sum_{i=1}^m\mu_i\xi_i \\
其中 & \alpha_i \geq 0; \mu_i \geq 0 \quad 两者都是拉格朗日乘子 \notag
\end{align}

对偶问题是拉格朗日函数的极大极小问题。首先求\(\mathcal{L}(w,b,\xi,\alpha,\mu)\)对\(w,b,\xi\)求极小，分别求导并令导数为0

\begin{align}
\nabla_w \mathcal{L}(w,b,\xi,\alpha,\mu) & = w - \sum_{i=1}^m \alpha_i y^{(i)} x^{(i)} = 0 \\
\nabla_b \mathcal{L}(w,b,\xi,\alpha,\mu) & = -\sum_{i=1}^m \alpha_i y^{(i)} = 0 \\
\nabla_{\xi_i} \mathcal{L}(w,b,\xi,\alpha,\mu) & = C - \alpha_i -\mu_i = 0
\end{align}

得到

\begin{align}
w=\sum_{i=1}^m \alpha_i y^{(i)} x^{(i)} \\
\sum_{i=1}^m \alpha_i y^{(i)} = 0 \\
C- \alpha_i -\mu_i = 0
\end{align}

将结果带入原问题的拉格朗日函数，

\begin{align}
min_{w,b,\xi} \mathcal{L}(w,b,\xi,\alpha,\mu) = -\frac{1}{2}\sum_{i=1}^m\sum_{i=1}^m \alpha_i\alpha_j 
y^{(i)}y^{(j)} \langle x^{(i)}x^{(j)} \rangle + \sum_{i=1}^m\alpha_i
\end{align}

再对\(min_{w,b,\xi}\mathcal{L}(w,b,\xi,\alpha,\mu)\)求参数\(\alpha\)的极大，就得到了对偶问题目标函数的表达式，连同上面得
到的约束，共同构成对偶问题：

\begin{align}
max_\alpha \quad & = -\frac{1}{2}\sum_{i=1}^m\sum_{i=1}^m \alpha_i\alpha_j y^{(i)}y^{(j)} 
\langle x^{(i)}x^{(j)}\rangle + \sum_{i=1}^m\alpha_i \\
s.t. \quad & = \sum_{i=1}^m \alpha_i y^{(i)} = 0 \\
& C - \alpha_i - \mu_i = 0, \quad i=1,2,\ldots,m \\
& \alpha_i = 0, \quad i=1,2,\ldots,m \\
& \mu_i \geq = 0, \quad i=1,2,\ldots,m
\end{align}

最后利用倒数第三个等式约束消去变量\(\mu_i\)，只留下变量\(\alpha_i\)，得到\(0 \leq \alpha_i \leq C\)，同时将目标函数中的
输入属性的內积\(\langle x^{(i)},x^{(j)} \rangle\)替换成核函数\(\langle \phi(x^{(i)}),\phi(x^{(j)}) \rangle\)，并且直接使
用核函数的最终形式\(K(x^{(i)},x^{(j)})\)得到对偶问题的最终形式

\begin{align}
max_{\alpha} \quad & W(\alpha) = \sum_{i=1}^m \alpha_i - 
\frac{1}{2} \sum_{i,j=1}^m y^{(i)}y^{(j)} \alpha_i\alpha_j K( x^{(i)},x^{(j)} ) \\
s.t. \quad & 0 \leq \alpha_i \leq C, \quad i = 1,2,\ldots,m \\
& \sum_{i=1}^m \alpha_i y^{(i)} = 0
\end{align}

***** Kernel
使用核函数的方法：将原始输入的属性值\(x\)变换成\(\phi(x)\)特征作为算法的输入（仅此而已，不知道为什么原来就一直没有看懂）。
只是在具体运用时利用了一点小技巧，并不是直接去计算映射后的值然后再去计算，而是先将原始输入属性值表示称內积的形式，然后巧
妙的用核函数来代替內积。这样做的优势：将核函数代替內积可以高效计算；同时可以将特征映射到高维空间，从而将原来线性不可分的
问题转换成线性可分。

一般来说，如果输入空间\(x^{(i)} \in \mathbb{R}^n\)，对应的标记有两类\(y^{(i)} \in \{-1,1\}\)，如果能用\(\mathbb{R}^n\)中
的一个超曲面将正负实例正确分开，则称这个问题为非线性可分问题。而非线性问题往往不好求解，一般采取非线性变换， *将非线性问
题转换成线性问题* ，通过求解变换后的线性问题来得到原来的非线性问题的解。

用线性分类方法求解非线性问题分为两步：首先使用一个变换将原空间的数据映射到新空间；然后在新空间里用线性分类学习方法从训练
数据中学习分类模型。核技巧就是这样的方法。支撑向量机使用核技巧的基本想法就是通过一个非线性变换将输入空间对应到一个特征空
间，使得在输入空间\(\mathbb{R}^n\)中的超曲面对应于特征空间\(\mathcal{H}\)中的超平面，这样学习任务通过在特征空间中求解线
性支持向量机就可以完成。其中输入空间为欧式空间\(\mathbb{R}^n\)或离散空间，特征空间为希尔伯特空间\(\mathcal{H}\)（no see）。

设\(\mathcal{X}\)是输入空间，\(\mathcal{H}\)为特征空间，如果存在一个从\(\mathcal{X}\)到\(\mathcal{H}\)的映射，
\[\phi(x):\mathcal{X} \to \mathcal{H} \]使得对所有的\(x,z \in \mathcal{X}\)，函数\(K(x,z)\)满足\[K(x,z)=\phi(x) \cdot
\phi(z)\]则称\(K(x,z)\)为核函数。

核函数的想法是，在学习和预测时，只使用核函数\(K(x,z)\)，而不显示的定义映射函数\(\phi\)，这将比直接计算\(\phi(x) \cdot
\phi(z)\)容易的多。由于算法中所有的属性值（例如目标函数和决策函数）都可以表示成內积的形式\(\langle x,z \rangle\)，因为需
要将所有的\(x\)都替换成\(\phi(x)\)，那么直接将內积替换成\(\langle\phi(x),\phi(z)\rangle\)的形式，而
\(\langle\phi(x),\phi(z)\rangle\)就是一个核函数，直接带入\(K(x,z)\)的表达式就可以。最终结果就是将算法中所有的內积都直接
替换成核函数即可；根本无需计算映射，也根本无需知道映射函数的表达式，只需要使用核函数的最终表达式。而且核函数并不单单可以
应用在支撑向量机上，所有可以将输入属性表示成內积的形式的算法都可以使用。

对于给定的核\(K(x,z)\)，特征空间\(\mathcal{H}\)和映射函数\(\phi\)的取法并不唯一。特征空间可以不同，即便在同一个特征空间
也可以取不同的映射。

TODO 举一个核函数和映射函数表达式的例子

*核函数的选取：* 有时可以选择标准的核函数，有时需要自己根据问题构造核函数（需要阅读相应的论文来了解怎样为一个新问题发明
一个新的核函数）。

通常所说的核函数就是正定核函数（positive definite kernel function）。根据 Mercer 定理，正定核函数的 *充要条件* ：设已知
\(K:\mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R} \)，则\(K(x,z)\)是正定核函数的充要条件是对任意
\(\{x^{(1)},x^{(2)},\ldots,x^{(m)}\},\ (m < \infty) \)，相应的核矩阵 Gram 矩阵\(K=[ K(x^{(i)},x^{(j)}) ]_{m \times m} \)
是对称半正定的。

*常用核函数:* 高斯核函数（Gaussian kernel function）\[ K(x,z) = exp \left( -\frac{||x-z||^2}{2\sigma^2} \right) \] 多项
式核函数（polynomial kernel function）\[ K(x,z) = (x^T z +c)^d \] 字符串核函数（string kernel function）

支撑向量机，通过核函数将数据映射到高维空间只是增大了数据线性可分的可能性，但无法确保映射后一定线性可分。因此需要使用
\(\ell 1\)正则化来修正模型；同时也使得分割线对 outliers 不那么敏感。

***** 决策函数
决策函数即算法最终得到的分离超平面的表达式。分离超平面\(w^*,b^*\)的表达式由原问题通过满足 KKT 条件求解得到，而表达式中参
数具体的值由对偶问题通过 SMO 算法求得。原问题可以表示为

\begin{align}
min_{w, b,\xi_i} \quad & \frac{1}{2}||w||^2 + C\sum_{i=1}^m \xi_i \\
s.t. \quad & -[y^{(i)} \left( w \cdot x^{(i)} + b \right) - 1 + \xi_i] \leq 0, \quad i=1,2,\ldots,m \\
& -\xi_i \leq 0, \quad i=1,2,\ldots,m
\end{align}

拉格朗日函数

\begin{align}
\mathcal{L}(w,b,\xi,\alpha,\mu) = & \frac{1}{2}||w||^2 + C\sum_{i=1}^m\xi_i \notag \\
& - \sum_{i=1}^m\alpha_i[y^{(i)}(w \cdot x^{(i)} + b)-1 + \xi_i] - \sum_{i=1}^m\mu_i\xi_i 
\end{align}

解满足 KKT 条件

\begin{align}
& \partial_w\mathcal{L}(w^*,b^*,\xi^*,\alpha^*,\mu^*) = w^* - \sum_{i=1}^m \alpha_i^* y^{(i)} x^{(i)} = 0 \\
& \partial_b\mathcal{L}(w^*,b^*,\xi^*,\alpha^*,\mu^*) = -\sum_{i=1}{m} \alpha_i^* y^{(i)} = 0 \\
& \partial_{\xi}\mathcal{L}(w^*,b^*,\xi^*,\alpha^*,\mu^*) = C - \alpha^* - \mu^* = 0 \\
& \alpha_i^* [y^{(i)} \left( w \cdot x^{(i)} + b \right) - 1 + \xi_i] = 0 \\
& \mu_i^* \xi_i^* = 0 \\
& -[y^{(i)} \left( w \cdot x^{(i)} + b \right) - 1 + \xi_i] \leq 0 \\
& -\xi_i^* \leq 0 \\
& \alpha_i^* \geq 0 \\
& \mu_i^* \geq 0
\end{align}

求解上面的方程，\(w^*\)较易求解。再由 KKT 对偶互补条件可知，当存在\(\alpha_i^*\)满足\(0 < \alpha_i^* < C\)时，
\(y^{(i)}(w^* \cdot x^{(i)} + b^*) - 1 = 0\)，从而可求得\(b^*\)。其中会利用一个小技巧\(y^{(i)} \cdot y^{(i)} = 1\)，并用
核函数替换內积最终得到

\begin{align}
w^* & = \sum_{i=1}^m \alpha_i^* y^{(i)} x^{(i)} \\
b^* & = y^{(i)} - \sum_{i=1}^m \alpha_i^* y^{(i)} K(x^{(i)}, x^{(j)}) \\
& \sum_{i=1}^m \alpha_i^* y^{(i)} K(x \cdot x^{(i)} ) + b^* = 0 \\
f(x) & = sign \left( \sum_{i=1}^m \alpha_i^* y^{(i)} K(x \cdot x^{(i)}) + b^* \right)
\end{align}

***** 支撑向量
在线性不可分的情况下，将对偶问题的解中对应\(\alpha_i^* > 0\)的样本点\((x^{(i)},y^{(i)})\)称为支撑向量。软间隔的支撑向量
可能在任何地方：可以在间隔边界上；可以在间隔边界与分离超平面之间；也可以在分离超平面误分的一侧。
+ 若\(\alpha_i^* < C\)，则\(\xi_i=0\)：支撑向量落在边界线上
+ 若\(\alpha_i^* = C, \quad 0 < \xi_i < 1\)，则分类正确：支撑向量在间隔边界与分离超平面之间
+ 若\(\alpha_i^* = C, \quad \xi_i = 1\)，则支撑向量位于分离超平面上
+ 若\(\alpha_i^* = C, \quad \xi_i > 1\)，则支撑向量位于分离超平面误分的一侧
note：\(0 \leq \alpha_i^* \leq C, \quad 1-\xi_i\)是函数间隔；只有\(\alpha_i \ne 0\)对应的样本点才是支撑向量？？？可能
KKT 对偶互补条件中两个变量都为零？？？ TODO


***** Sequential Minimal Optimization
*坐标上升法：* 当求解多变量最优化问题且不存在约束的时候，可以使用坐标上升法（和梯度下降法以及牛顿法都是最优化方法）来求
解。利用两层循环来实现，外层循环便利所有样本，内层循环便利所有变量。在内层循环中每次仅优化一个变量，同时固定其他的变量不
变，针对该变量来优化目标函数。这样总是沿着和坐标轴平行的方向取得最大值，而且选取往最优解移动的速度最快的变量来求解。

序列最小最优化算法求解的对象是凸二次规划的对偶问题：

\begin{align}
max_{\alpha} \quad & W(\alpha) = \sum_{i=1}^m \alpha_i - 
\frac{1}{2} \sum_{i,j=1}^m y^{(i)}y^{(j)} \alpha_i\alpha_j K(x^{(i)},x^{(j)}) \\
s.t. \quad & 0 \leq \alpha_i \leq C, \quad i = 1,2,\ldots,m \\
& \sum_{i=1}^m \alpha_i y^{(i)} = 0
\end{align}

在该问题中变量是拉格朗日乘子\(\alpha_i\)，每个样本都有一个拉格朗日乘子，变量的总数等于训练样本的个数\(m\)

算法基本思路：因为 KKT 条件是该最优化问题的充分必要条件，当所有变量都满足该最优化问题的 KKT 条件，那么这个最优化问题的解
就得到了。否则，选择两个变量，固定其他变量，针对这两个变量构建二次规划问题，而求解该二次规划子问题将使得目标函数值变大。
这样将问题不断分解为子问题，并对子问题求解，直到所有的变量都满足 KKT 条件。

由于构建的二次规划子问题可以通过解析的方法求解，这样就大大提高了整个算法的计算速度（迭代会很耗时的）。另外由于约束
\(\sum_{i=1}^m \alpha_i y^{(i)} = 0\)的存在，无法只更改一个变量，因为当其他的变量值都不改变时，该变量的值也会由于约束的存在
而固定无法改变。所以子问题每次都会同时更新两个变量，在满足约束的条件下来求解二次规划问题。

SMO 是启发式算法：好像两个变量的选择方法是启发式搜索算法（不确定）。

整个 SMO 算法包括两个部分：\(\textcircled{1}\)求解两个变量二次规划的解析方法；\(\textcircled{2}\)选择变量的启发式方法。

****** 两个变量二次规划的求解方法
每个子问题都可以转换成一个变量的二次函数，很容易求得解析解。

假设利用启发式方法选择出两个变量\(\alpha_1,\alpha_2\)，其他变量\(\alpha_3,\alpha_4,\ldots,\alpha_m\)固定不变，由约束可知
\( \alpha_1 y^{(1)} + \alpha_2 y^{(2)} = -\sum_{i=3}^{m} \alpha_i y^{(i)} \)由于公式右侧是固定的，使用一个常量符号
\(\zeta\)替代

\begin{equation}
\alpha_1 y^{(1)} + \alpha_2 y^{(2)} = \zeta
\end{equation}

虽然要同时更新两个变量，但其实只有一个自由变量。此处使用\(\alpha_2\)表示\(\alpha_1\)，利用\({(y^{(1)})}^2 = 1\)

\begin{equation}
\alpha_1 = ( \zeta - \alpha_2 y^{(2)} ) y^{(1)}
\end{equation}

因此目标函数可以写成

\begin{equation}
W(\alpha_1,\alpha_2,\ldots,\alpha_m) = W((\zeta - \alpha_2 y^{(2)})y^{(1)},\alpha_2,\alpha_3,\ldots,\alpha_m)
\end{equation}

由于将\(\alpha_3,\alpha_4,\ldots,\alpha_m\)视为固定值，目标函数可以看做关于\(alpha_2\)的二次函数，可以写成
\(a\alpha_2^2 + b\alpha_2 + c\)的形式，在没有约束的情况下，可以很容易的通过求导并令导数为零得到极值。

同时每个变量都必须满足约束\(0 < \alpha_i < C\)，具体到一个子问题上，对于变量\(\alpha_1,\alpha_2\)，两个变量都必须约束在
\([0,C] \times [0, C]\)的方框中，再加上上面的线性约束，\(\alpha_1,\alpha_2\)必须约束在被方框截断的直线上。从而\(L \leq
\alpha_2^{new} \leq H\)，其中L与H是\(\alpha_2^{new}\)所在的对角线段端点的界。另外线性约束中的常量\(\zeta\)可以用
\(\alpha_1 \pm \alpha_2\)表示

\begin{align}
& if \ y^{(1)} \neq y^{(2)} \notag \\
& L=max(0, \alpha_2^{old} - \alpha_1^{old}),  H=min(C,C+\alpha_2^{old}-\alpha_1^{old}) \\
& if \ y^{(1)} = y^{(2)} \notag \\
& L=max(0,\alpha_2^{old} + \alpha_1^{old}-C), H=min(C,\alpha_2^{old}+\alpha_2{old}) 
\end{align}

先只要求满足线性约束，求解得到\alpha_2^{new,unclipped} 然后再裁剪来满足 box constraints

\begin{align}
\alpha_2^{new} = \left\{ \begin{array}{} H & if \alpha_2^{new,unclipped} > H \\
\alpha_2^{new,unclipped} & if L \leq \alpha_2^{new,unclipped} \leq H \\
L & if \alpha_2^{new,unclipped} < L \end{array} \right.
\end{align}

再利用线性约束求得\(\alpha_1^{new}\)

\begin{equation}
\alpha_1^{new} = \alpha_1^{old} + y^{(1)}y^{(2)} (\alpha_2^{old} - \alpha_2^{new})
\end{equation}

\(\alpha_2\)的求解：为了叙述方便，记\[g(x)=\sum_{i=1}^m \alpha_i y^{(i)} K(x^{(i)},x) + b\] 令
\[E_i = g(x^{(i)}) - y^{(i)} = (\sum_{j=1}^m \alpha_j y^{(j)} K(x^{(j)},x^{(i)}) + b) - y^{(i)}, \quad i=1,2 \]
用于表示g(x)对输入x^{(i)}的预测值与真实值y^{(i)}之差。最终可得

\begin{align}
\alpha_2^{new,unclipped} = \alpha_2^{old} + \frac{y^{(2)} (E_1 - E_2)}{\eta} \\
\eta = K_{11} + K_{22} -2K_{12} = ||\phi(x^{(1)}) - \phi(x^{(2)}||^2
\end{align}

其中\(\phi(x)\)是输入空间到特征空间的映射

****** 变量选择方法
SMO 称第一个变量的选择为外层循环，第二个变量的选择为内层循环。外层循环在训练样本中选择违反 KKT 条件最严重的样本点，将其
对应的变量作为第一个变量。内层循环的标准是希望选择的变量有足够大的变化。

\begin{align}
KKT 条件 \notag \\
\alpha_i = 0 \Leftrightarrow y^{(i)}g(x^{(i)}) \geq 1 \\
0 < \alpha_i < C \Leftrightarrow y^{(i)}g(x^{(i)})=1 \\
\alpha_i = C \Leftrightarrow y^{(i)}g(x^{(i)}) \leq 1 \\
其中 g(x^{(i)}) = \sum_{j=1}^m \alpha_j y^{(j)} K(x^{(i)}, x^{(j)}) + b
\end{align}

外层循环首先遍历所有满足条件\(0 < \alpha_i < C\)的样本点，即在间隔边界上的支撑向量点，检验他们是否满足 KKT 条件；如果这
些样本点都满足 KKT 条件，那么遍历整个训练集，检验他们是否满足 KKT 条件。这里的满足 KKT 条件都有一定的误差容忍范围，典型
值为0.001~0.01。什么叫做违反最严重？实际值与要求值差别比较大？ TODO

内层循环选择\(\alpha_2\)，由于\(\alpha_2^{new}\)依赖于\(|E_1 - E_2|\)，一种简单的做法是通过使\(|E_1 - E_2|\)最大来使得
\(\alpha_2\)有足够大的变化。由于\(\alpha_1\)已经确定，\(E_1\)也随之确定。如果\(E_1\)是正的，那么选择最小的\(E_i\)作为
\(E_2\)；如果\(E_1\)是负的，那么选择最大的\(E_i\)作为\(E_2\)。

为了节省计算时间，将所有的\(E_i\)值保存在一个列表中。

在特殊情况下，如果内层循环通过以上方法选择的\(\alpha_2\)不能使目标函数有足够的上升，那么采用以下启发式规则继续选择
\(\alpha_2\)。遍历在间隔边界上的支撑向量点，依次将其对应的变量作为\(\alpha_2\)试用，直到目标函数有足够的上升。若找不到合
适的\(\alpha_2\)，那么遍历训练数据集；若仍找不到合适的\(\alpha_2\)，则放弃之前选择的\(\alpha_1\)，再通过外层循环寻找另外
的\(\alpha_1\)。注：这里目标函数是上升还是下降要看目标函数具体是在求最大还是最小。

计算阈值\(b\)和差值\(E_i\)：在每次完成两个变量的优化后，都要重新计算阈值\(b\)。当\(0 < \alpha_1^{new} < C\)时，由 KKT 条
件可知\(\sum_{i=1}^m \alpha_i y^{(i)} K_{i1} + b = y^{(1)}\)和\(E_1\)的定义

\(E_1 = \sum_{i=3}^m \alpha_i y^{(i)} K_{i1} + \alpha_1^{old}y^{(1)}K_{11} + \alpha_2^{old}y^{(2)}K_{21} + b^{old} - y^{(1)}\)可知

\begin{align}
b_1^{new} & = y^{(1)} - \sum_{i=3}^m \alpha_i y^{(i)} K_{i1} - \alpha_1^{new}y^{(1)}K_{11} - \alpha_2^{new}y^{(2)}K_{21}
\\
& = -E_1 - y^{(1)}K_{11}(\alpha_1^{new} - \alpha_1^{old}) - y^{(2)}K_{21}(\alpha_2^{new} - \alpha_2^{old}) + b^{old}
\end{align}

同样，如果\(0 < \alpha_2^{new} < C)，那么

\begin{align}
b_2^{new} = -E_2 - y^{(1)}K_{12}(\alpha_1^{new} - \alpha_1^{old}) - y^{(2)}K_{22}(\alpha_2^{new} - \alpha_2^{old}) + b^{old}
\end{align}

如果\(\alpha_1^{new},\alpha_2^{new}\)同时满足\(0 < \alpha_i^{new} < C, i=1,2\)，那么\(b_1^{new}=b_2^{new}\)；如果
\(\alpha_1^{new},\alpha_2^{new} = 0 \ or \ C\)，那么\(b_1^{new},b_2^{new}\)以及他们之间的数都满足 KKT 条件，这时选择
\(b_1^{new},b_2^{new}\)的中点作为\(b^{new}\)。

另外再每次更新完两个变量后，还必须更新对应的\(E_i\)值，并将他们保存到列表中。

\begin{align}
E_i^{new} = \sum_S y^{(j)} \alpha_j K(x^{(i)},x^{(j)}) + b^{new} - y^{(i)}
\end{align}

其中S是所有支撑向量\(x^{(j)}\)的集合。

**** 算法演绎
***** Support Vector Regression
支撑向量回归(SVR)假设我们能容忍 f(x) 与 y 之间最多有 \(\epsilon\) 的偏差，即仅当 f(x) 与 y 之间的差别绝对值大于
\(\epsilon\) 时才计算损失。

周志华 P133

***** Semi-Supervised Support Vector Machine
半监督支撑向量机(S3VM)

Transductive Support Vector Machine(TSVM)

周志华 P298

*** Expectation-Maximization

期望最大化算法(EM)用于解决含有隐变量的问题。隐变量(latent variable)表示未观测变量，用 z 表示；x 表示观测变量(observable
variable)；\(\theta\) 表示参数。并且通常若 z 可观测，那么将很容易求解最大似然。EM 算法是一种迭代式的方法，其 *基本思想*
是：若参数 \(\theta\) 已知，则可根据训练数据推断出最优隐变量 z的值（E 步）；反之，若 z 的值已知，则可方便的对参数
\(\theta\) 做极大似然估计（M 步）。

求最大似然函数一般是选择参数使数据的概率最大，EM 算法中，只观察到 x ，所以只求 x 的概率。EM 算法使用对数极大似然估计来求
解来求解参数 \(\theta\) ，同时利用联合分布(x,z)来计算边缘分布(x)。通过对 z 计算期望，来最大化已观测数据的对数边缘似然
(marginal likelihood)。

\begin{align}
\ell (\theta) & = ln \mathcal{P}(x; \theta) \\
& = ln \sum_z \mathcal{P}(x,z; \theta) \\
& = ln \left( \sum_z \mathcal{P} (x|z;\theta) \mathcal{P}(z;\theta) \right)
\end{align}

直接求取 \(\ell (\theta)\) 会比较困难，所以使用如下策略：
+ 不断的构建 \(\ell\) 的一个下界(E-step)；
+ 然后求取下界的最大值(M-step)

EM 算法原型：以初始值 \(\theta^{0}\) 为起点，对上式迭代执行以下步骤直至收敛，
+ 基于 \(\theta^{t}\) 推断隐变量 z 的期望，记为 z^t;
+ 基于已观测变量 x 和 z^t 对参数 \(\theta\) 做极大似然估计，记为 \(\theta^{t+1}\);

进一步，若不是求取 z 的期望，而是基于 \(\theta^{t}\) 计算隐变量 z 的概率分布 \(\mathcal{P}(z|x;\theta^{t})\) ，从而得到
Q 函数。

EM 算法的核心是 Q 函数(Q function)：完全数据的对数似然函数 \(ln \mathcal{P} (x,z; \theta) \) 关于在给定观测数据 x 和当前
参数 \(\theta^{t}\) 下对未观察数据 z 的条件概率分布 \(\mathcal{P}(z|x;\theta)\) 的期望

\begin{align}
Q(\theta,\theta^{t}) & = E_{z|x;\theta^{t}} [ ln \mathcal{P}(x,z;\theta) ] \\
& = E_z [ \left( ln \mathcal{P}(x,z;\theta) \right) | x; \theta^{t} ] \\
& = \sum_z \left( ln \mathcal{P} (x,z;\theta) \right) \mathcal{P}(z|x;\theta^{t})
\end{align}

\(Q(\theta, \theta^{t})\) 的第一个变元表示要极大化的参数，第二个变元表示参数的当前估计值。
\(\mathcal{P}(z|x;\theta^{t})\)是在给定观测数据 x 和当前估计参数 \(\theta^{t}\) 下隐变量 z 的条件概率分布。

*EM 算法* 输入：观测数据 x ，隐变量 z ，联合分布 \(\mathcal{P} (x,z;\theta)\) ，条件分布 \(\mathcal{P} (z|x;\theta)\) ；
 输出：模型参数 \(\theta\) 
1. 选择参数的初值 \(\theta^{0}\) ，开始迭代；
2. E-step：记 \(\theta^{t}\) 为第 t 次迭代参数 \(\theta\) 的估计值，在第 t+1 次迭代的 E 步，计算 Q 函数 \(Q(\theta,
   \theta^{t})\) \[ Q(\theta,\theta^{t}) = \sum_z \left( ln \mathcal{P} (x,z;\theta) \right)
   \mathcal{P}(z|x;\theta^{t})\] 需要先求解 \(\mathcal{P}(z|x;\theta^{t})\)
3. M-step：求使 \(Q(\theta, \theta^{t})\) 极大化的 \(\theta\) ，确定第 t+1 次迭代的参数估计值 \(\theta^{t+1}\)
   \[ \theta^{t+1} = arg max_{\theta} Q(\theta, \theta^{t}) \]
4. 重复 E-step 和 M-step ，直到收敛。一般是用较小的正数 \(\epsilon_1,\epsilon_2\)，若满足 \(||\theta^{t+1}|| <
   \epsilon_1 \ or \ ||Q(\theta, \theta^{t+1}) - Q(\theta, \theta^{t})|| < \epsilon_2 \) 则停止迭代。

EM 算法说明：EM 算法对初值是敏感的；每次迭代实际在求 Q 函数并极大化，每次迭代都是似然函数增大或达到局部极值；

EM 算法可看做一种非梯度的优化方法，可以看成是坐标上升法：E-step 在最大化；  M-step 在 \(\theta\) 方向最大化

**** EM 收敛性
EM 算法最大的优点是简单性和普适性。

**** 三硬币模型
假设有 3 枚硬币，分别记做 A、B、C ，三枚硬币正面出现的概率分别是 \(p_a, p_b, p_c \) 。进行如下掷硬币试验：先掷硬币 A，根
据其结果选择下一次需要掷的硬币，正面选硬币 B，反面选硬币 C；然后掷选出的硬币，出现正面记作 1，反面记作 0；独立地重复 n
次，观察结果为 1,1,0,1,0,0,1,1,0,1,1,1,0 ，假设只能观察到最终掷硬币的结果，不能观测掷硬币的过程。如何估计三枚硬币正面出
现的概率，即三硬币模型的参数？

李航 P155

**** EM 算法的推广

李航 P166

*** Bayesian Decision Theory

贝叶斯决策论是概率框架下实施决策的基本方法：分类任务在所有相关概率都已知的理想情形下，如何基于这些概率和误判损失来选择最
优的类别标记。

贝叶斯判定准则(Bayes decision rule)：为最小化总体风险，只需要在每个样本上选择那个能使条件风险 \(\varepsilon(c|x)\) 最小
的类别标记，即 \(h^*(x) = arg min_{c \in \mathcal{Y}} \varepsilon(c | x) \) ，此时 \(h^*\) 称为 *贝叶斯最优分类器*
(Bayes optimal classifier)，与之相对应的总体风险 \(\varepsilon(h^*)\) 称为贝叶斯风险(Bayes risk)，\(1 -
\varepsilon(h^*)\) 反应了贝叶斯分类器所能达到的最好性能，即通过机器学习所能产生的模型精度的理论上限。

贝叶斯定理：

\begin{equation}
P(c|x) = \frac{P(c) P(x|c)}{P(x)} \label{bayes:bayes}
\end{equation}

*** Naive Bayes

利用贝叶斯公式 \(\eqref{bayes:bayes}\)来估计后验概率 \(P(c|x)\) 的主要困难在于类条件概率 \(P(x|c)\) 是所有属性上的联合概
率，难以从有限的训练样本直接估计而得。朴素贝叶斯假设属性条件独立(attribute conditional independent assumption)：对已知类
别，所有属性相互独立，也就是每个属性独立的对分类结果发生影响。基于该假设，贝叶斯公式可以重写为（d 为属性的数目，\(x_i\)
是 x 的第 i 个属性上的取值。

\begin{equation}
P(c|x) = \frac{P(c)P(x|c)}{P(x)} = \frac{P(c)P(x_1,x_2,\ldots,x_d|c)}{P(x)} = \frac{P(c) \prod_{i=1}^d P(x_i|c)}{P(x)}
\end{equation}

由于对所有类别来说 P(x) 相同，根据贝叶斯判定准则可得朴素贝叶斯分类器的表达式为

\begin{equation}
y = arg max_{c \in \mathcal{Y}} P(c) \prod_{i=1}^d P(x_i|c)
\end{equation}

** Unsupervised Learning
无监督学习

** Semi-supervised Learning
半监督学习

** Reinforcement Learning
强化学习

** Computational Learning Theory
计算学习理论用于真正理解机器学习算法，了解怎样修改算法；区分开真正了解算法与只看了书和公式的人，真正成为一个好的木匠。

思考：
+ 学习器(机器的或非机器的)应遵循什么样的规则？
+ 是否可能独立于学习算法确定学习问题中固有的难度？
+ 能否知道为保证成功的学习有多少训练是必要的或充足的？
+ 能否刻画出一类学习问题中固有的计算复杂度？
对所有这些问题的一般回答还未知。这里着重讨论只给定目标函数的训练样例和候选假设空间的条件下,对该未知的目标函数的归纳学习
问题。

该理论致力于回答如下的问题:
+ 在什么样的条件下成功的学习是可能的？
+ 在什么条件下一特定的学习算法可保证成功运行？
+ 我们真正关心的是泛化误差，却为什么始终在努力减小经验误差？
+ bias / variance 的准确定义
+ 需要多少训练样例才足以成功地学习到目标函数，定量的上下界
+ 学习器在达到目标前会有多少次出错，定量的上下界

为了解决这些问题，需要许多特殊的条件假设：
+ 怎样定义学习得到的结果是成功的？是必须找到目标概念？还是以较大的概率得到目标概念的近似？
+ 学习器如何得到训练样本？学习器自己由实验获取？还是按照某过程随机的生成而不受学习器的控制？


中心极限定理：在某种一条件下，大量随机变量之和的分布逼近于正态分布。

learning theory split to two central questions:
1. can we make sure that Eout(g) is close enough to Ein(g) ?
2. can we make Ein(g) small enough ?

*** Probably Approximately Correct
概率近似正确，简称 PAC：通常我们无法精确的学到目标概念（concept）。原因如下：
+ 由于训练集 D 往往只包含有限数量的样本，因此，通常会存在一些在 D 上的“等效”的假设，学习算法无法区分。即存在多个假设都满
  足样本空间到标记空间的映射
+ 从分布\(\mathcal{D}\)上采样得到 D 的过程有一定的偶然性。存在一定的概率使得样本都有某种特性，但该特性在总体中不存在；从
  而对同样大小的不同训练集，学的的结果也可能有所不同
因此我们希望以比较大的把握学的比较好的模型；即以 *较大的概率* 学的 *误差满足预设上限* 的模型。也就成为了“概率”“近似正确”
框架。

假设输入空间\(\mathcal{X}\)中所有样本服从一个 /隐含未知/ 的分布\(\mathcal{D}\)，训练集 D 中所有样本都是独立地从这个分布
上采样而得（独立同分布：independent and identically distribution， 简称 i.i.d)。通常假设训练集和测试集服从相同的分布（在
深度学习中，通常无法保证训练集和测试集分布形同）；训练集的样本独立同分布。

训练样本集 D 中所有从隐含未知分布 \(\mathcal{D}\) 上独立采样得到，h 是一个从输入空间 \(\mathcal{X}\) 到标记空间
\(\mathcal{Y}\) 的一个映射，h 在 D 上的经验误差（也就是训练误差）为\[ \hat{\varepsilon}(h;D) = \frac{1}{m}
\sum_{i=1}^{m} \mathit{1}(h(x^{(i)} \ne y^{(i)}) \]泛化误差为\[ \varepsilon(h;\mathcal{D}) = P_{x \sim \mathcal{D}}
(h(x) \ne y) \]由于 D 是\(\mathcal{D}\) 的独立同分布采样，因此 *h 的经验误差的期望等于其泛化误差。* 即\[ E[
\hat{\varepsilon}(h;D) ] = \varepsilon(h; \mathcal{D}) \]

note：均值是观察样本的平均值，尽管随机变量一样，但观察到的样本不同，均值很可能不同；期望是一个数学特征，针对于一个随机变
量。根据大数定律（随机变量序列的前一些项的算术平均值，在某种条件下，收敛到这些项的均值的算术平均值），期望是均值随着样本
趋于无穷时的极限。频率的稳定性是概率定义的客观基础。

PAC 可学习(PAC Learnable)：只要从分布\(\mathcal{D}\)中独立同分布采样得到的样例数目 m ，满足\(m \geq
poly(\frac{1}{\epsilon},\frac{1}{\delta},size(x),size(c))\)，学习算法能从假设空间\(\mathcal{H}\)中 PAC 辨识概念类
\(\mathcal{C}\)，则称概念类\(\mathcal{C}\)对假设空间\(\mathcal{H}\)而言是 PAC 可学习的，有时也简称概念类\(\mathcal{C}\)
是 PAC 可学习的。若算法运行的时间也是多项式函数\(poly(\frac{1}{\epsilon},\frac{1}{\delta},size(x),size(c))\)，则称概念类
\(\mathcal{C}\)是高效 PAC 可学习的(efficiently PAC learnable)，称算法 L 是概念类\(\mathcal{C}\)的 PAC 学习算法。

*仅仅要求了训练样本的个数和时间满足一个多项式函数。*

假定学习算法处理每个样本的时间为常数，则算法的时间复杂度等价于样本复杂度。于是我们对算法时间复杂度的关心就转化成对样本复
杂度的关心。满足 PAC 学习算法 L 所需的\(m \geq poly(\frac{1}{\epsilon},\frac{1}{\delta},size(x),size(c))\)中最小的 m ，
称为学习算法 L 的 *样本复杂度。*

不可知 PAC 可学习(agnostic PAC learnable)：

当 \(c \not \in \mathcal{H}\) 时，学习算法无法得到目标概念 c 的 \(\epsilon\) 近似。但是在假设空间 \(\mathcal{H}\) 中必存
在一个泛化误差最小的假设，找到此假设的 \(\epsilon\) 近似也不失为一个较好的目标。这是不可知学习。


PAC 学习给出了一个抽象地刻画机器学习能力的框架，基于这个框架能对很多重要的问题进行理论探讨：
+ 研究某任务在什么样的条件下可学得较好的模型？
+ 某算法在什么样的条件下可进行有效的学习？
+ 需多少训练样例才能获得较好的模型？

PAC 学习中一个关键因素是假设空间\(\mathcal{H}\)的复杂度；\(\mathcal{H}\)包含了学习算法 L 的所有可能输出，一般而言，
\(\mathcal{H}\)越大，其包含任意目标概念的可能性越大，但从中找到某个具体目标概念的难度也越大。\(|\mathcal{H}|\)有限时，我
们称\(\mathcal{H}\)为有限假设空间，否则称为无限假设空间。


*** 有限假设空间
**** 可分情形
目标概念 c 属于假设空间 \(\mathcal{H}\) 就是可分情形。

有限假设空间 \(\mathcal{H}\) 都是 PAC 可学习的。

**** 不可分情形
目标概念 c 不属于假设空间 \(\mathcal{H}\) 就是不可分情形。假定对于任何 \(h \in \mathcal{H}, \ \hat{\varepsilon}(h) \ne
0\) 即 \(\mathcal{H}\) 中任何一个假设都会在训练集上出现或多或少的错误。根据霍夫丁不等式可得： *当样例数目 m 较大时，h的
经验误差是其泛化误差很好的近似* 。

*** Vapnik-Chervonenkis Dimension

VC维用于刻画假设空间的复杂度。VC 维的定于与数据分布 \(\mathcal{D}\) 无关（在数据分布未知时，仍能计算出假设空间的VC维）

给定假设空间 \(\mathcal{H}\) 和示例集 \(D=\{x^{(1)},x^{(2)},\ldots,x^{(m)}\}, \mathcal{H} \)中每个假设 h 都能对 D 中示例
赋予标记，标记结果可表示为 \(h|_D = \{(h(x^{(1)}),h(x^{(2)}),\dots,h(x^{(m)})) \}\) 随着 m 的增大，\(\mathcal{H}\) 中所
有假设对 D 中的示例所能赋予标记的可能结果数也会增大（可能这就是其称为增长函数的原因）。另外对于相同的 m 不同的假设空间所
能赋予的可能结果数也不相同。

Growth Function，增长函数：描述了假设空间 \(\mathcal{H}\) 的表示能力。具体定义为：增长函数 \(\prod_{\mathcal{H}} (m)\)表
示假设空间 \(\mathcal{H}\) 对 m 个示例所能赋予标记的 *最大可能结果数* 。\(\mathcal{H}\) 对示例所能赋予标记的可能结果数越
大，\(\mathcal{H}\) 的表示能力越强，对学习任务的适应能力越强；反应了假设空间的复杂度。

Dichotomy，对分：对二分类问题来说，\(\mathcal{H}\) 中的假设对 D 中示例赋予标记的 *每种可能结果* 称为对 D 的一种对分；每
个假设会把示例集分为两类，因此称为对分。

Shattering，打散：若假设空间 \(\mathcal{H}\) 能实现对示例集 D 的 *所有对分* ，即 \(\prod_{\mathcal{H}} = 2^m\) ，则称示
例集D 能被假设空间 \(\mathcal{H}\) 打散。


现实学习任务所面临的通常是无限假设空间。假设空间无限和 VC 维有限的关系？？


*假设空间 \(\mathcal{H}\) 的 VC 维是能被 \(\mathcal{H}\) 打散的 /最大示例集/ 的大小，* 即

\begin{equation}
VC(\mathcal{H}) = max\{ m: \prod_{\mathcal{H}} (m) = 2^m \}
\end{equation}

通常计算 VC 维的方法：若存在大小为 d 的示例集能被 \(\mathcal{H}\) 打散，但不存在任何一个大小为 d + 1 的示例集能被
\(\mathcal{H}\) 打散，则 \(\mathcal{H}\) 的 VC 维是 d。

增长函数的上界（增长函数与 VC 维的关系）
若假设空间 \(\mathcal{H}\) 的 VC 维为 d，

\begin{align}
& \prod_{\mathcal{H}} \leq \sum_{i=0}^{d} \left( \array {m \\ i} \right), \quad m \in \mathbb{N}, Sauer 引理 \\
& \prod_{\mathcal{H}} \leq \left( \frac{e \cdot m}{d} \right) ^d, \quad m > d, 推论
\end{align}

增长函数可用于估计经验误差与泛化误差之间的关系：对假设空间 \(\mathcal{H}, m \in \mathbb{N}, 0 < \epsilon < 1, 任意 \in
\mathcal{H}\) 有

\begin{equation}
P \left( \left| \varepsilon(h) - \hat{\varepsilon}(h) \right| > \epsilon \right) \leq 
4\prod_{\mathcal{H}} (2m) exp(- \frac{m\epsilon^2}{8})
\end{equation}

泛化误差界：只与样本个数 m 有关；基于 VC 维的泛化误差界是分布无关(distribution-free)、数据独立(data-independent)的。
*定理：* 若假设空间 \(\mathcal{H}\) 的 VC 维为 d，则对任意 \(m > d, \ 0 < \delta < 1, h \in \mathcal{H}\) 有

\begin{equation}
P \left( \left| \varepsilon(h) - \hat{\varepsilon}(h) \right| \leq \sqrt{\frac{8dln\frac{2em}{d} + 
8ln\frac{4}{\delta}}{m}} \right) \geq 1 - \delta
\end{equation}

也就是说使用假设类 \(\mathcal{H}\) ，训练样本个数要是 \(VC(\mathcal{H})\) 的线性同阶函数才能够确保能够学的一个较好的假设。
一般来说，对大多数假设类，其VC维数大约是其参数个数的线性阶。结合这两者，大致可以得到， *训练样本的个数一般要求为参数个数
的线性同阶* 。理论针对的是独立同分布的随机变量，对于最坏的情况仍然是符合的；实际选取的样本，通常会比较好，并不需要那么多
样本来训练。


*定理：任何 VC 维有限的假设空间 \(\mathcal{H}\) 都是（不可知） PAC 可学习的。* 满足经验风险最小化(Empirical Risk
Minimization, ERM)原则。


**** 为什么 SVM 不会过拟合
核函数只是将特征映射到了无穷维，但具有较大间隔的线性分类器 VC 维都比较低。VC 维的上界并不依赖特征 X 的维数，SVM 会自动找
到一个 VC 维低的假设类，而不会过拟合。\(\mathcal{H}\) 只包含较大间隔的线性分类器，间隔最小为 r，假设 \(||x^{(i)}||_2
\leq R, then VC(\mathcal{H}) \leq \lceil \frac{R^{2}}{4r^{2}} \rceil + 1 \)

*** Rademacher Complexity

Rademacher 复杂度是另一种刻画假设空间复杂度的途径，但在一定程度上考虑了数据分布。

基于 VC 维的泛化误差界是分布无关、数据独立的；也就是对任何数据分布都成立，使得基于 VC 维的学习结果具有一定的普适性。但由
于没有考虑数据自身，基于 VC 维得到的泛化误差界通常比较松（如果考虑数据的分布可能会得到更加确切的泛化误差界），对那些与学
习问题的典型情况相差甚远的较坏的分布来说尤其如此？？？？？？？TODO

给定训练集 \(D=\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\ldots,(x^{(m)},y^{(m)})\}, y^{(i)} = \pm 1\) ，假设 h 的经验误差为

\begin{align}
\hat{\varepsilon}(h) & = \frac{1}{m} \sum_{i=1}^{m} \mathit{1} (h(x^{(i)}) \ne y^{(i)}) \notag \\
& = \frac{1}{m} \sum_{i=1}^{m} \frac{1-y^{(i)}h(x^{(i)}}{2} \notag \\
& = \frac{1}{2} - \frac{1}{2m} \sum_{i=1}^{m} y^{(i)} h(x^{(i)})
\end{align}

其中 \(\frac{1}{m} \sum_{i=1}^m y^{(i)}h(x^{(i)})\) 体现了预测值 \(h(x^{(i)}\) 与样例真实标记 \(y^{(i)}\) 之间的一致性
（值越大，表明两者越一致，经验误差越小；若训练样本没有错分的情况则取最大值 1）。也就是说经验误差最小的假设是

\begin{equation}
arg max_{h \in \mathcal{H}} \frac{1}{m} \sum_{i=1}^m y^{(i)}h(x^{(i)})
\end{equation}

然而现实任务中样例的标记有时会收到噪声的影响，即由于收到某些随机因素的影响，样例的标记不再是真实的标记。此时选择假设空间
在训练接（？？？）上表现最好的假设，有时还不如选择事先考虑了随机噪声的假设。

Rademacher 随机变量： 以 0.5 的概率取 -1，0.5 的概率取 +1 的随机变量 \(\sigma_i\) 称为 Rademacher 随机变量。

基于 Rademacher 随机变量的经验误差最小假设： \[ sup_{h \in \mathcal{H}} \frac{1}{m} \sum_{i=1}^{m} \sigma_i h(x_i) \] 由
于 \(\mathcal{H}\) 是无限假设空间，有可能取不到最大值，因此使用上确界代替最大值。考虑 \(\mathcal{H}\) 中所有假设，对上式
求期望可得（严重不明白取期望的原因，已经是在所有假设中取经验误差最小的那个假设了，为什么还要取期望？？？）\[ E_{\sigma}
\left[ sup_{h \in \mathcal{H}} \frac{1}{m} \sum_{i=1}^{m} \sigma_i h(x_i) \right] \] 该式体现了假设空间 \(\mathcal{H}\)
的表达能力。当假设空间中只有一个假设时，该式的值为 0；当有 2^m 个假设时且 \(\mathcal{H}\) 能打散 D 时，该式的值为 1。

令 \(Z = \{z^{(1)}, z^{(2)}, \ldots, z^{(m)}\}, z^{(i)} \in \mathcal{Z}; \quad \mathcal{F}:\mathcal{Z} \to \mathbb{R}\)
其中 \(\mathcal{Z}\) 和 \(\mathbb{R}\) 都是实数域，\(\mathcal{F}\) 是从 \(\mathcal{Z}\) 到 \(\mathbb{R}\) 的映射簇。则
函数空间 \(\mathcal{F}\) 关于 Z 的经验 Rademacher 复杂度和关于 \(\mathcal{Z}\) 上分布 \(\mathcal{D}\) 的 Rademacher 复杂
度分别为下面两个式子

\begin{align}
\hat{\varepsilon}_Z (\mathcal{F}) & = E_\sigma \left[ sup_{f \in \mathcal{F}} \frac{1}{m} 
\sum_{i=1}^m \sigma_i f(z^{(i)}) \right] \\

\varepsilon_m (\mathcal{F}) & = E_{Z \in \mathcal{Z}:|Z|=m} \left[ \hat{\varepsilon}_Z (\mathcal{F}) \right] 
\end{align}

经验 Rademacher 复杂度衡量了函数空间 \(\mathcal{F}\) 与随机噪声在集合 Z 中的相关性；下式表明函数空间 \(\mathcal{F}\) 在
\(mathcal{Z}\) 上关于分布 \(\mathcal{F}\) 的相关性。

基于 Rademacher 复杂度可得关于函数空间 \(\mathcal{F}\) 的泛化误差界。

*** 稳定性

算法的稳定性研究的是算法在输入发生变化时，输出是否会随之发生较大的变化。

无论是基于 VC 维还是 Rademacher 复杂度来推导泛化误差界，所得到的结果均与具体学习算法无关，适用于所有学习算法。稳定性分析
不必考虑假设空间中所有可能的假设，只需要根据算法自身的特性来讨论输出假设的泛化误差界。

学习算法 L 关于损失函数 \(\ell\) 满足 \(\beta -\) 均匀稳定性。

基于学习算法的均匀稳定性可以得到学习算法学得假设的泛化误差界。

*若学习算法L是ERM且稳定的，则假设空间 \(\mathcal{H}\) 可学习。*

稳定性与假设空间并无关系，但两者通过算是函数 \(\ell\) 联系起来。

*** 不等式定理

The union bound ：\(A_1,A_2,\ldots,A_k\)是 k 个不同的事件，可能并不独立，那么

\begin{equation}
P(A_1 \cup A_2 \cup \ldots \cup A_k) \leq P(A_1) + P(A_2) + \ldots + P(A_k)
\end{equation}

Jensen inequality：对任意的凸函数 f(x) ，有

\begin{equation}
f(E[x]) \leq E[f(x)]
\end{equation}

Hoeffding inequality，霍夫丁不等式：若\(x_1,x_2,\ldots,x_m\)为 m 个独立随机变量，且满足 \(0 \leq x_i \leq 1\)，则对任意
\(\epsilon > 0\)，有 

\begin{align}
& P \left( \frac{1}{m} \sum_{i=1}^{m} x_i - \frac{1}{m} \sum_{i=1}^{m} E(x_i) \geq \epsilon \right) \leq 
exp(-2m \epsilon^2) \\
& P \left( \left| \frac{1}{m} \sum_{i=1}^{m} x_i - \frac{1}{m} \sum_{i=1}^{m} E(x_i) \right| \geq \epsilon \right) \leq
2exp(-2m \epsilon^2)
\end{align}

McDiarmid inequality：若\(x_1,x_2,\ldots,x_m\)为 m 个独立随机变量，且对任意 \(1 \leq i \leq m\)，函数 f 满足
\[ sup_{x_1,\ldots,x_m,x_i^,} | f(x_1,\ldots,x_m) - f(x_1,\ldots,x_{i-1},x_i^,,x_{i+1},\ldots,x_m) | \leq c_i \]
则对任意 \(\epsilon > 0\)，有

\begin{align}
& P(f(x_1,\ldots,x_m) - E[f(x_1,\ldots,x_m)] \geq \epsilon ) \leq exp(\frac{-2\epsilon^2}{\sum_i c_i^2}) \\
& P( | f(x_1,\ldots,x_m) - E[f(x_1,\ldots,x_m)] | \geq \epsilon ) \leq 2exp(\frac{-2\epsilon^2}{\sum_i c_i^2}) 
\end{align}

*** 术语
*concept* 概念：表示从样本空间\(\mathcal{X}\)到标记空间\(\mathcal{Y}\)的映射，用符号 c 表示。不要疑惑为什么叫做概念，在机
器学习中，这个映射就被称为概念。

*目标概念* ：若对任何样例\((x,y)\)都有\(c(x)=y\)成立，则称 c 为目标概念。

*concept class* 概念类：我们希望学的的目标概念构成的集合称为概念类，用符号\(\mathcal{C}\)表示。no see 概念类到底是个什么
东西？？？？

*hypothesis space* 假设空间：对给定的学习算法 L ，她所考虑的所有可能概念的集合称为假设空间，用符号\(\mathcal{H}\)表示。
学习算法吧自认为可能的目标概念一起构成\(\mathcal{H}\)，学习算法并不可能知道概念类的真实值，因此\(\mathcal{C}\)和
\(\mathcal{H}\)通常是不同的。假设空间中任何一个假设\(h \in \mathcal{H}\)也都是从样本空间\(\mathcal{X}\)到标记空间
\(\mathcal{Y}\)的映射。

*consistent* 一致的：若目标概念 \(c \in \mathcal{H}\) ，则表示\(\mathcal{H}\)中存在假设能将所有示例按照与真实标记一致的
方式分开，则称该问题对学习算法 L 是 /可分的/ (separable)，也称为一致的；若 \(c \not \in \mathcal{H}\)，则称为不可分
(non-separable)或者不一致(non-consistent)

*PAC Identity* PAC 辨识：对\(0 < \epsilon, \delta < 1\)，所有\(c \in \mathcal{C}\)和所有的分布\(\mathcal{D}\)，若存在学
习算法 L ，其输出假设\(h \in \mathcal{H}\)满足\[ P(\varepsilon(h) \leq \epsilon ) \geq 1 - \delta \]则称学习算法能从假设空间
\(\mathcal{H}\)中 PAC 辨识概念类\(\mathcal{C}\)



* 附

** AI-ML-DL
人工智能就是想让计算机拥有自行处理高级任务的能力；机器学习是实现人工智能的一种方法；深度学习是一类具体的机器学习方法。
*** Artificial Intelligence
人工智能发展：
+ 推理期 -- 赋予机器逻辑推理能力，但没有知识
+ 知识期 -- 让机器拥有知识（专家系统）；由人来把知识总结出来再教给计算机
+ 机器学习 -- 让机器自己能够学习知识

*** Machine Learning
机器学习研究方法：
+ 连接主义（connectionism）学习 -- 代表：感知机、神经网络、深度学习
+ 符号主义（symbolism）学习 -- 代表：决策树
+ 统计学习 -- 代表：SVM、核方法；（跟上述两种方法并不是完全并列）

*** Deep Learning
深度学习
**** 现在火热的原因
+ 数据量大了
+ 计算能力强了

**** 降低门槛
以往机器学习技术在应用中要取得良好的性能，对使用者的要求较高；而深度学习只要超参调节的好，性能往往就很好，显著降低了机器
学习应用者的门槛。

手工调参：参数的设置缺乏理论指导，参数调节上失之毫厘，学习结果谬以千里；使用需要大量的 track （窍门）

**** 理论基础
深度学习缺乏严格的理论基础

** 归纳偏好
任何一个有效的机器学习算法必有其归纳偏好，否则他将被假设空间中看似在训练集上等效的假设所迷惑，而无法产生确定的学习结果。

*** No Free Lunch Theorem -- NFL
没有免费的午餐定理：所有问题出现的机会相同，或所有问题同等重要的前提下，无论算法 A 看似多精妙，算法 B 多笨拙，他们的期望
性能是相同的。即：若考虑所有潜在的问题，则所有学习算法都一样好。学习算法自身的归纳偏好与问题是否匹配，往往起到决定行的作
用。

脱离具体问题，空泛的谈什么学习算法更好毫无意义。

*** Occam's Razor
奥卡姆剃刀原理：在所有可能选择的模型中，能够很好的解释已知数据并且十分简单才是最好的模型。

* 心得






