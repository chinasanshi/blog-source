** 性能检查工具

*** gprof

Profiling 用于剖析代码，相关的信息需要由编译器增加，即需要指定 -pg 编译选项编译。可以定位系统时间消
耗位置，以及程序运行时的函数调用关系。利用这些信息可以定位出程序性能较差的地方，被多次调用的函数或者
定位出一些不容易发现的 bug 。当程序非常大或者非常复杂而难以分析的时候，profiling 就派上用场了，因为
profiler 只收集程序运行时的信息。也就是说程序怎样运行直接决定了profile的内容。剖析的结果有多种输出形
式： *plat profile* 显示了每个函数的花费时间以及被调用次数； *call graph* 显示函数的调用关系，方便分
析每个分析的时间消耗； *annotated source* 显示了程序每一行执行的次数。下面 [[https://sourceware.org/binutils/docs/gprof/][gprof]] 官方的英文简介：

Profiling allows you to learn where your program spent its time and which functions called which
other functions while it was executing. This information can show you which pieces of your program
are slower than you expected, and might be candidates for rewriting to make your program execute
faster. It can also tell you which functions are being called more or less often than you expected.
This may help you spot bugs that had otherwise been unnoticed.

Since the profiler uses information collected during the actual execution of your program, it can be
used on programs that are too large or too complex to analyze by reading the source. However, how
your program is run will affect the information that shows up in the profile data. If you don't use
some feature of your program while it is being profiled, no profile information will be generated
for that feature.

Profiling has several steps:
1. You must compile and link your program with profiling enabled.  -pg 
2. You must execute your program to generate a profile data file. 
3. You must run gprof to analyze the profile data. 

Several forms of output are available from the analysis.

+ The flat profile shows how much time your program spent in each function, and how many times that
  function was called. If you simply want to know which functions burn most of the cycles, it is
  stated concisely here. 
+ The call graph shows, for each function, which functions called it, which other functions it
  called, and how many times. There is also an estimate of how much time was spent in the
  subroutines of each function. This can suggest places where you might try to eliminate function
  calls that use a lot of time. 
+ The annotated source listing is a copy of the program's source code, labeled with the number of
  times each line of the program was executed.

Quickstart
1. 使用 -pg -g 选项编译程序 $ gcc -pg -g foo.c -O2 -o foo # 可以指定优化级别
2. 运行应用程序 $ ./foo # 会在当前目录生成 gmon.out 文件
3. 使用 gprof 工具来分析 gmon.out ，分析时需要关联可执行程序文件 

#+BEGIN_SRC shell
$ gprof foo gmont.out -p # plant ，查看每个函数执行时间
$ gprof foo gmont.out -q # call graph ，函数调用关系、调用次数、花费时间
$ gprof foo gmont.out -A # annotated ，在程序源代码的上，注释每一行代码执行的次数
#+END_SRC


如果希望从共享库（包括 C 库 libc.a）中获得剖析信息，就需要使用 -pg 来编译这些库。幸运的是，很多发行
版都提供了已经启用代码剖析支持而编译的 C 库版本（libc_p.a）。对于没有按照标准提供 libc_p 的发行版本
来说，需要检查它是否可以单独安装，或者可能需要自己下载 glibc 的源代码并进行编译。

*注意：* gprof 只能分析应用程序在 ~运行过程中~ 所消耗掉的用户时间，无法统计系统消耗时间。gprof 通过
 以固定的周期对程序运行时间进行采样测量来工作的，如果花在用户空间执行的时间与花在内核中睡眠的时间相
 比非常小，就会被取整成零。同时程序不运行时，就不会对程序进行采样测量。这意味着剖析不会受到系统中其
 他事件的影响（例如另外一个用户使用了大量的 CPU 时间）；但难以优化消耗大量系统时间的程序代码。

Gprof 对多线程支持不好，因为 gprof 用 ITIMER_PROF 信号，而只有主线程才能处理这个信号。只有进程退出才
能生成gmon.out文件，用起来还是有些不方便。退出是指程序是按照自身的运行逻辑正常退出的，如果直接
killall -9 是不能得到统计结果的。实际中采用 SIGTERM 信号的方式，使用 kill -15 ，发送 SIGTERM 信号给
程序，程序中会有相应的函数捕捉该信号，捕捉到该信号后，置一个退出标记，这样我们就可以控制程序按照既定
的逻辑在处理完一次完整的工作后正常的退出。

其他的剖析工具：[[http://oprofile.sourceforge.net][Oprofile]] 、[[http://www.sysprof.com][sysprof]] 、google 的 [[https://github.com/gperftools/gperftools][gperftools]] 


** 性能优化背景

+ IPC :: 每个时钟周期内的指令数，IPC 偏低表明代码没有很好地利用 CPU 。
+ cache :: 内存读写是很快的，但还是无法和处理器的指令执行速度相比。为了从内存中读取指令和数据，处理
           器需要等待，用处理器的时间来衡量，这种等待非常漫长。Cache 是一种 SRAM，它的读写速率非常快，
           能和处理器处理速度相匹配。因此将常用的数据保存在 cache 中，处理器便无须等待，从而提高性能。
           Cache 的尺寸一般都很小，充分利用 cache 是软件调优非常重要的部分。
+ pipeline :: 流水线为了提升 CPU 的并行处理能力，CPU 内部会有多级流水线，分别用于一条指令的多个步骤：
              取指令、分析指令、执行指令。从而使得 CPU 达到每个时钟周期近似执行一条指令的效果。要求
              相邻的指令相互没有依赖关系。假如某条指令需要依赖前面一条指令的执行结果数据，那么
              pipeline 便失去作用，因为第二条指令必须等待第一条指令完成。因此好的软件必须尽量避免这
              种代码的生成。
+ superscalar :: 超标量指一个时钟周期发射多条指令的流水线机器架构，比如 Intel 的 Pentium 处理器，内
                 部有两个执行单元，在一个时钟周期内允许执行两条指令。
+ 乱序执行 :: 在处理器内部，不同指令所需要的处理步骤和时钟周期是不同的，如果严格按照程序的执行顺序执
          行，那么就无法充分利用处理器的流水线。因此指令有可能被乱序执行。

+ 分支预测 :: 分支指令对软件性能有比较大的影响。尤其是当处理器采用流水线设计之后，假设流水线有三级，
          当前进入流水的第一条指令为分支指令。假设处理器顺序读取指令，那么如果分支的结果是跳转到其他
          指令，那么被处理器流水线预取的后续两条指令都将被放弃，从而影响性能。为此，很多处理器都提供
          了分支预测功能，根据同一条指令的历史执行记录进行预测，读取最可能的下一条指令，而并非顺序读
          取指令。分支预测对软件结构有一些要求，对于重复性的分支指令序列，分支预测硬件能得到较好的预
          测结果，而对于类似 switch case 一类的程序结构，则往往无法得到理想的预测结果。
+ PMU :: performance monitor unit ，处理器特性对软件的性能有很大的影响，然而依赖时钟进行定期采样的
         profiler 模式无法揭示程序对这些处理器硬件特性的使用情况。处理器厂商针对这种情况，在硬件中加
         入了 PMU 单元。PMU 允许软件针对某种硬件事件设置 counter，此后处理器便开始统计该事件的发生次
         数，当发生的次数超过 counter 内设置的值后，便产生中断。比如 cache miss 达到某个值后，PMU 便
         能产生相应的中断。捕获这些中断，便可以考察程序对这些硬件特性的利用效率了。
+ Tracepoint :: 散落在内核源代码中的一些 hook，一旦使能，它们便可以在特定的代码被运行到时被触发，这
                一特性可以被各种 trace/debug 工具所使用。Perf 就是该特性的用户之一。假如您想知道在应
                用程序运行期间，内核内存管理模块的行为，便可以利用潜伏在 slab 分配器中的 tracepoint。
                当内核运行到这些 tracepoint 时，便会通知 perf。Perf 将 tracepoint 产生的事件记录下来，
                生成报告，通过分析这些报告，调优人员便可以了解程序运行时期内核的种种细节，对性能症状
                作出更准确的诊断。



** 性能优化
性能优化有三个层次：

+ 系统层次 :: 系统层次关注系统的控制流程和数据流程，优化主要考虑如何减少消息传递的个数；如何使系统的
          负载更加均衡；如何充分利用硬件的性能和设施；如何减少系统额外开销（比如上下文切换等）。
+ 算法层次 :: 算法层次关注算法的选择（用更高效的算法替换现有算法，而不改变其接口）；现有算法的优化
          （时间和空间的优化）；并发和锁的优化（增加任务的并行性，减小锁的开销）；数据结构的设计（比
          如lock-free的数据结构和算法）。
+ 代码层次 :: 代码层次关注代码优化，主要是cache相关的优化（I-cache,D-cache相关的优化）；代码执行顺序
          的调整；编译优化选项；语言相关的优化技巧等等。

性能优化需要相关的工具支持，这些工具包括编译器的支持；CPU 的支持；以及集成到代码里面的测量工具等等。
这些工具主要目的是测量代码的执行时间以及相关的 cache miss, cache hit 等数据，这些工具可以帮助开发者
定位和分析问题。

性能优化和性能设计不同。性能设计贯穿于设计，编码，测试的整个环节，是产品生命周期的第一个阶段；而性能
优化，通常是在现有系统和代码基础上所做的改进，属于产品生命周期的后续几个阶段（假设产品有多个生命周
期）。性能优化不是重新设计，性能优化是以现有的产品和代码为基础的，而不是推倒重来。性能优化的方法和技
巧可以指导性能设计，但两者的方法和技巧不能等同。两者关注的对象不同。性能设计是从正向考虑问题：如何设
计出高效，高性能的系统；而性能优化是从反向考虑问题：在出现性能问题时，如何定位和优化性能。性能设计考
验的是开发者正向建设的能力，而性能优化考验的是开发者反向修复的能力。两者可以互补。
 

下面是一个代码优化技巧列表

1) Code adjacency （把相关代码放在一起），推荐指数：5颗星

把相关代码放在一起有两个涵义，一是相关的源文件要放在一起；二是相关的函数在 object 文件里面，也应该是
相邻的。这样，在可执行文件被加载到内存里面的时候，函数的位置也是相邻的。相邻的函数，冲突的几率比较小。
而且相关的函数放在一起，也符合模块化编程的要求：那就是 高内聚，低耦合。

如果能够把一个 codepath 上的函数编译到一起（需要编译器支持，把相关函数编译到一起）， 很显然会提高
I-cache 的命中率，减少冲突。但是一个系统有很多个 code path，所以不可能面面俱到。不同的性能指标，在优
化的时候可能是冲突的。所以尽量做对所以 case 都有效的优化，虽然做到这一点比较难。

2) Cache line alignment （cache对齐），推荐指数：4颗星

数据跨越两个 cacheline，就意味着两次 load 或者两次 store。如果数据结构是 cacheline 对齐的，就有可能
减少一次读写。数据结构的首地址cache line对齐，意味着可能有内存浪费（特别是数组这样连续分配的数据结
构），所以需要在空间和时间两方面权衡。

3) Branch prediction （分支预测），推荐指数：3颗星（不推荐静态分支预测）

代码在内存里面是顺序排列的。对于分支程序来说，如果分支语句之后的代码有更大的执行几率，那么就可以减少
跳转，一般 CPU 都有指令预取功能，这样可以提高指令预取命中的几率。分支预测用的就是 likely/unlikely 这
样的宏，一般需要编译器的支持，这样做是静态的分支预测。现在也有很多 CPU 支持在 CPU 内部保存执行过的分
支指令的结果（分支指令的 cache），所以静态的分支预测就没有太多的意义。如果分支是有意义的，那么说明任
何分支都会执行到，所以在特定情况下，静态分支预测的结果并没有多好，而且 likely/unlikely 对代码有很大
的侵害（影响可读性），所以一般不推荐使用这个方法。

4) Data prefetch (数据预取），推荐指数：4颗星

指令预取是CPU自动完成的，但是数据预取就是一个有技术含量的工作。数据预取的依据是预取的数据马上会用到，
这个应该符合空间局部性（spatial locality），但是如何知道预取的数据会被用到，这个要看上下文的关系。一
般来说，数据预取在循环里面用的比较多，因为循环是最符合空间局部性的代码。

但是数据预取的代码本身对程序是有侵害的（影响美观和可读性），而且优化效果不一定很明显（命中的概率）。
数据预取可以填充流水线，避免访问内存的等待，还是有一定的好处的。

5) Memory coloring （内存着色），推荐指数：不推荐

内存着色属于系统层次的优化，在代码优化阶段去考虑内存着色，有点太晚了。所以这个话题可以放到系统层次优
化里面去讨论。

6）Register parameters （寄存器参数），推荐指数：4颗星

寄存器做为速度最快的内存单元，不好好利用实在是浪费。但是，怎么用？一般来说，函数调用的参数少于某个数，
比如 3，参数是通过寄存器传递的（这个要看 ABI 的约定）。所以，写函数的时候，不要带那么多参数。c 语言
里还有一个 register 关键词，不过通常都没什么用处（没试过，不知道效果，不过可以反汇编看看具体的指令，
估计是和编译器相关）。尝试从寄存器里面读取数据，而不是内存。

7) Lazy computation （延迟计算），推荐指数：5颗星

延迟计算的意思是最近用不上的变量，就不要去初始化。通常来说，在函数开始就会初始化很多数据，但是这些数
据在函数执行过程中并没有用到（比如一个分支判断，就退出了函数），那么这些动作就是浪费了。

变量初始化是一个好的编程习惯，但是在性能优化的时候，有可能就是一个多余的动作，需要综合考虑函数的各个
分支，做出决定。

延迟计算也可以是系统层次的优化，比如 COW(copy-on-write) 就是在 fork 子进程的时候，并没有复制父进程所
有的页表，而是只复制指令部分。当有写发生的时候，再复制数据部分，这样可以避免不必要的复制，提供进程创
建的速度。

8] Early computation （提前计算），推荐指数：5颗星

有些变量，需要计算一次，多次使用的时候。最好是提前计算一下，保存结果，以后再引用，避免每次都重新计算
一次。函数多了，有时就会忽略这个函数都做了些什么，写程序的人可以不了解，但是优化的时候不能不了解。能
使用常数的地方，尽量使用常数，加减乘除都会消耗 CPU 的指令，不可不查。

9）Inline or not inline （inline函数），推荐指数：5颗星

Inline or not inline，这是个问题。Inline 可以减少函数调用的开销（入栈，出栈的操作），但是 inline 也
有可能造成大量的重复代码，使得代码的体积变大。Inline 对 debug 也有坏处（汇编和语言对不上）。所以用这
个的时候要谨慎。小的函数（小于10行），可以尝试用 inline；调用次数多的或者很长的函数，尽量不要用
inline。

10) Macro or not macro (宏定义或者宏函数），推荐指数：5颗星

Macro 和 inline 带来的好处，坏处是一样的。但我的感觉是，可以用宏定义，不要用宏函数。用宏写函数，会有
很多潜在的危险。宏要简单，精炼，最好是不要用。中看不中用。

11) Allocation on stack （局部变量），推荐指数：5颗星

如果每次都要在栈上分配一个 1K 大小的变量，这个代价是不是太大了哪？如果这个变量还需要初始化（因为值是
随机的），那是不是更浪费了。全局变量好的一点是不需要反复的重建，销毁；而局部变量就有这个坏处。所以避
免在栈上使用数组等变量。

12) Multiple conditions （多个条件的判断语句），推荐指数：3颗星

多个条件判断时，是一个逐步缩小范围的过程。条件的先后，决定了前面的判断是否多余的。根据code path 的情
况和条件分支的几率，调整条件的顺序，可以在一定程度上减少 code path 的开销。但是这个工作做起来有点难
度，所以通常不推荐使用。

13) Per-cpu data structure (非共享的数据结构），推荐指数：5颗星

Per-cpu data structure 在多核，多 CPU 或者多线程编程里面一个通用的技巧。使用 Per-cpu datastructure
的目的是避免共享变量的锁，使得每个 CPU 可以独立访问数据而与其他 CPU 无关。坏处是会消耗大量的内存，而
且并不是所有的变量都可以 per-cpu 化。并行是多核编程追求的目标，而串行化是多核编程里面最大的伤害。有
关并行和串行的话题，在系统层次优化里面还会提到。

局部变量肯定是threadlocal的，所以在多核编程里面，局部变量反而更有好处。

14) 64 bits counter in 32 bits environment （32位环境里的64位counter），推荐指数：5颗星

32 位环境里面用 64 位 counter 很显然会影响性能，所以除非必要，最好别用。有关 counter 的优化可以多说
几句。counter 是必须的，但是还需要慎重的选择，避免重复的计数。关键路径上的 counter 可以使用 per-cpu
counter，非关键路径(exception path）就可以省一点内存。

15) Reduce call path or call trace （减少函数调用的层次），推荐指数：4颗星

函数越多，有用的事情做的就越少（函数的入栈，出栈等）。所以要减少函数的调用层次。但是不应该破坏程序的
美观和可读性。个人认为好程序的首要标准就是美观和可读性。不好看的程序读起来影响心情。所以需要权衡利弊，
不能一个程序就一个函数。

16) Move exception path out （把exception处理放到另一个函数里面），推荐指数：5颗星

把 exceptionpath 和 critical path 放到一起（代码混合在一起），就会影响 critical path 的 cache 性能。
而很多时候，exception path 都是长篇大论，有点喧宾夺主的感觉。如果能把 criticalpath 和 exception path
完全分离开，这样对 i-cache 有很大帮助。

17) Read, write split （读写分离），推荐指数：5颗星

在 cache.pdf 里面提到了伪共享(false sharing)，就是说两个无关的变量，一个读，一个写，而这两个变量在一
个 cache line 里面。那么写会导致 cache line 失效（通常是在多核编程里面，两个变量在不同的 core 上引
用）。读写分离是一个很难运用的技巧，特别是在 code 很复杂的情况下。需要不断地调试，是个力气活（如果有
工具帮助会好一点，比如 cache miss 时触发 cpu 的 execption 处理之类的）。

18) Reduce duplicated code（减少冗余代码），推荐指数：5颗星

代码里面的冗余代码和死代码(deadcode)很多。减少冗余代码就是减小浪费。但冗余代码有时又是必不可少
（copy-paste太多，尾大不掉，不好改了），但是对 critical path，花一些功夫还是必要的。

19) Use compiler optimization options （使用编译器的优化选项），推荐指数：4颗星

使用编译器选项来优化代码，这个应该从一开始就进行。写编译器的人更懂 CPU，所以可以放心地使用。编译器
优化有不同的目标，有优化空间的，有优化时间的，看需求使用。

20) Know your code path （了解所有的执行路径，并优化关键路径），推荐指数：5颗星

代码的执行路径和静态代码不同，它是一个动态的执行过程，不同的输入，走过的路径不同。我们应该能区分出主
要路径和次要路径，关注和优化主要路径。要了解执行路径的执行流程，有多少个锁，多少个原子操作，有多少同
步消息，有多少内存拷贝等等。这是性能优化里面必不可少，也是唯一正确的途径，优化的过程，也是学习，整理
知识的过程，虽然有时很无聊，但有时也很有趣。


何时应该优化

如果数据表明，性能确实没有达到指标，特别是当 profiler 表明，某处关键路径上的代码执行占用了大量的时间，
那么就是优化的时候了。
 

首先，要确保你要优化的代码是正确的，没有任何已知 bug。因为优化后的代码往往会变得更复杂而难以修改，所以要趁代码还比较简单的时候赶紧把bug都修掉吧。

然后，要确认性能指标，可以查 specification，或者如果不清楚的话再问问客户，或者根据其他功能性需求计算得出。用profiler收集目前的性能数据，和性能指标对比，以确定是否需要优化、哪里需要优化。（数据要保留，因为等优化完后还要用这些数据来做对比，以检查优化是否有效。）常见的profiler有Rational Quantify、Borland Optimizeit等等。很多UNIX下面都自带了profiler，比如prof、gprof等，对于一般的使用已经够了。

第三，进行优化。后面“常用的优化方法”一节对此进行了详细介绍。可以照着列出的常见的优化方法一个个地套用，或者更好的办法是进行一次团队头脑风暴会议，让大家提出各种可能的优化方案。记得优化时不要删除原来的实现。可以在源文件中以替代函数或者注释的方式保留原来的实现。

第四，使用profiler，验证优化是否如所想的那样有效。如果有效，那是最好；如果无效甚至是帮了倒忙，那么就赶紧取消改动，使用原来的版本，然后继续尝试其他的优化方案。记得优化要一步一步来，从最省事且最有效的方案到最麻烦且收益最小的方案。一旦达成性能指标就收手，不要恋战。

最后，记得对优化过的代码执行单元测试，看看有没有为了性能牺牲了正确性。要记得在注释或者文档中为优化留下记录。

 

常用的优化方法

最简单的优化：请检查是否使用了编译器的最新版本，是否把优化编译开关打开了，是否正确指定了目标处理器（以便使用MMX、SSE、3DNow!等高性能指令集以及让编译器自动为处理器所支持的其他高级特性做优化）。如果发布的产品要支持多种处理器，那么如果可能的话，请单独为每种处理器进行编译，分别发布，或者使用同一个发布包但让安装程序自动检测处理器型号并安装对应的二进制版本，或者把会在关键路径上执行的代码封装成动态链接库，然后让程序启动时自动检测处理器型号并加载为相应型号优化过的动态链接库版本。

还有，要确保使用了高性能的库，好的算法。比如，同样是从堆上分配内存，不同编译器提供的malloc或者new的实现，性能差异就不小。GCC使用的DL malloc就比较高效，Borland的编译器提供的实现使用了类似内存池的方式来动态管理内存，效率也很高，但也有些编译器对此并没有做什么优化，直接进行系统调用。不仅malloc/new如此，STL的allocator也是如此。SGI STL带的allocator为小于128字节的内存块的分配进行了特别优化（用内存池实现），所以小型字符串以及其他会用到allocator此项功能的操作都会性能比较好，但其他STL实现就没有做这样的优化。

选择正确的算法，往往比优化地实现算法更重要。因为不同时间复杂度的算法可能会给性能带来几个数量级的差异，而实现上的优化则往往付出很大、所得甚少。如果有时候精度不是那么重要，或者不需要找最佳的结果只需要找近似最佳的结果，那么往往可以用低时间复杂度的近似算法来代替。

另外，查表法也是个常用的技巧。假设，用某个公式可以把彩色图像转换成灰度图象，那么如果转换处理量很大的话，对每个象素都用该公式计算一边就不划算了，完全可以事先对所有颜色都计算好，然后处理时查表即可。对三角函数也是如此。当然，为了减小表的尺寸，在精度上往往需要牺牲一些。

但也不要以为因为是预先计算的不需要考虑计算代价，或者内存比较大虚拟内存更大，就可以把表做得很大。记住操作系统或者操作系统进行内存换页或者Cache换页都是要时间的，两个临界点分别是Cache的尺寸和物理内存的尺寸。具体是全部计算，还是全部查表，还是部分计算部分查表，表要做得多大，这些都需要尝试并用实际数据来支持。一个比较复杂的做法是动态地把计算出来的值缓存到稀疏表中并供以后使用时查询，表的物理尺寸根据当时机器的Cache、内存状况动态配置。

如果使用Java或者.NET上的编程语言的话，因为垃圾会占用空间，垃圾收集器的执行会占用时间，所以除了优化算法及其实现，还要注意你的代码对垃圾收集器是否友好。比如有没有及时把不用的引用置成null，有没有不必要的finalizer等等。

要避免很大的循环体，因为它们往往会超出Cache的尺寸。尽可能避免复杂的if-else或者switch-case语句，因为现代CPU的乱序执行功能看见这些语句会觉得很无奈。即便你非要用这些语句，最好养成习惯，把最可能的分支放在最前面。还有，如果可能的话，不要在循环体中使用这些条件分支语句。

有一些经典著作，如ThePractice of Programming（《程序设计实践》）、Programming Pearls（《编程珠玑》）、CodeComplete 2e（国内目前只出版了第1版，叫《代码大全》）也都提到了很多优化技术，但是，很重要的一点是，这些书都很少提到或者没有展开讲“构架设计时注意不要留下性能瓶颈或者缺陷”这个问题。这已超出了优化的范畴，而是要求在设计起始阶段时就考虑到性能需求。事实上，在硬件性能极大提高、优化编译器大行其道的今天，我们写程序时已基本上很少需要去考虑局部的微观实现是否优化了，因为有95%的可能编译器会替你去操心，或者根本性能不优化也可满足需求。甚至如果程序的内部结构比较清晰的化，算法也是可以很容易地替换的（比如用Strategy模式，或者Policy-Based Design的方式）。但也有的东西不太好在程序写完后再改，但又可能对性能有极大影响：那就是总体的设计和构架，以及一些影响面很广的设计决策/取舍。在今天，这些比较宏观的内容远比微观的优化技巧要重要。

读者可能要问了：“不是说‘不必要的优化是一切罪恶的源泉’、‘没有数据证明就不要做优化’吗？在设计起始阶段根本还没有代码可以执行，怎么获得数据？你怎么保证这不会是不必要的优化呢？”噢，这个问题很好回答：当设计还没形成，代码还没写时，这不叫优化，仅仅是设计。优化是一种改变，把现有的缓慢的东西变成快速的东西。而设计时“本来无一物，何来谈优化”呢。

更何况，一些比较宏观的构架上的决策，日后重构起来会非常困难，所以一开始就应该要考虑到。如果一开始需求尚未明确并且你也预计不到日后会有这样的性能需求，那么没有考虑到也不能怪你。但若一开始客户就提出了明确的性能要求，或者你心里很清楚客户一定会需要这样的性能，而你设计时却依然选择了无法或者难以满足这样性能要求的构架，那么这就不太好了。此外，如果两种设计/构架，并没有明确的实现复杂性或者优雅程度的差别，而其中一种设计/构架明显性能扩展性更好，那么也应该选择后一种。这不叫“premature optimization”，而叫做“避免premature pessimization”（过早悲观）（见C++ CodingStandards一书的Item 9）。

另外，还有一些很常见的和性能相关的话题。而且不少人对它们的认识还有一些误区，比如资源（特别是内存）的获取和释放、线程间的同步（也可看作特殊资源--各种线程锁的获取和释放）、字符串（或者其他缓冲区）的处理，以及这些操作的组合。这些话题很值得进一步讨论，在今后的文章中，会再和读者进行更深层次的交流。
 

分支优化

局部性优化

循环展开




** 优化程序性能

*** 编写高效程序

合适的数据结构和算法，编译器能够有效优化以转换为高效可执行代码的

源码，对处理量特别大的计算将任务分为多个部分；

程序优化：消除不必要的内容（函数调用，条件测试，存储器引用）；

使程序性能最大化：需要一个目标机器的模型，指明如何处理指令，以及各个操作的时序

特性；利用处理器提供的指令级并行能力同时执行多条指令；

降低计算不同部分之间的数据相关，增加并行度，同时执行；

研究程序的编译代码表示，是理解编译器以及产生的代码如何运行的最有效的手段之一；

确认关键路径，决定执行一个循环所需要的时间（至少是一个时间下界）；

关键路径是在循环的反复执行过程中形参的数据相关链；

 

*** 优化编译器的能力和局限性

（1）制定优化级别；

（2）编译器对程序只使用安全的优化，对于程序可能遇到的所有可能情况，优化后的程序和为优化的版本有一样的行为；（考虑指针指示位置是否相同，考虑运算数值是否相同，考虑存储器别名使用，考虑调用函数时对全局变量的修改）；

（3）使用内联函数替换对函数的调用，转换为函数体；

 

*** 程序性能表示

CPE每元素的周期数，表示程序性能并指导改进代码的方法；

用时钟周期表示，度量值表示的是指向了多少条指令而不是时钟运行的多快；

 

*** 消除循环的低效率

（1）（代码移动）将固定计算移出循环体，比如计算strlen，避免引入这样的渐进低效率；

（2）（减少过程调用）并没有很大提升（操作延迟）；

（3）（消除不必要的存储器引用）只在计算结束才存放，避免多次的读写；

 

*** 理解现代处理器

（1）优化程序性能，考虑利用处理器的微体系结构；

（2）延迟界限，下一条指令开始前这条指令必须执行结束；

吞吐量界限，刻画了处理器功能单元的原始计算能力，是程序性能的终极限制；

超标量，可以在每个时钟周期执行多个操作而且乱序的；

指令控制单元（ICU），从指令高速缓存中读取指令，并根据指令序列产生一组针对程序数据的基本操作；

执行单元（EU）执行操作；

（3）分支预测，投机技术，处理器开始取出位于他预测的分支会跳到的地方的指令并译码甚至在确定分支预测是否正确之前就开始执行；

指令译码；

加载存储，存储器读写；

退役单元，当确定下一条指令之后，才可以更改处理器的状态；

寄存器重命名，值可以直接从一个操作直接转发到另一个操作；

 

*** 功能单元的性能

（1）延迟，表示完成运算所需要的总时间；

（2）发射时间，表示两个连续的同类型运算之间需要的最小时钟周期数；

很短的发射时间是通过使用流水线实现的；

（3）发射时间表达的常用方法是指明功能单元的最大吞吐量，定义为发射时间的倒数，

延迟界限给出了任何必须按照严格顺序完成合并运算的函数所需要的最小CPE值；

根据功能单元产生结果的最大速率，吞吐量界限给出了CPE的最小界限；

 

*** 处理器抽象的数据模型

程序的数据流，展现不同操作之间的数据相关是如何限制他们的执行顺序的；

关键路径，是执行一组机器指令所需时钟周期数的一个下界；

 

*** 循环展开

减少了不直接有助于程序结构的操作的数量；

提供了一些方法进一步变化代码减少整个计算中关键路径上的操作数量；

循环展开，对浮点运算没有改进，因为每天mulss指令被翻译成两个操作：从存储器中加载一个数组元素，把这个值乘以已有的累积值；重新排列简化抽象，关键路径是n个mul操作，迭代次数减半，但每次迭代中还是有两个顺序的乘法操作；

这个关键路径是循环没有展开代码的性能制约因素；

 

*** 提高并行性

（1）多个累积变量，两路并行（奇偶性）；

（2）重新结合变换（结合律，括号放置）；

重新结合变换能够减少计算中关键路径上操作的数量，通过更好地利用功能单元的流水线能力得到更好的性能，大多数编译器不会尝试对浮点运算做重新结合，因为这些运算不保证是可结合的，当前的GCC版本会对整数运算执行重新结合，但是不是总有好的效果，通常，我们发现循环展开和并行地累积在多个值中，是提高程序性能的更可靠的方法。

（3）SSE达到更高并行度；

 

*** 限制因素

寄存器溢出；

分支预测和预测错误处罚；

（1）不要过分关心可预测的分支

（2）书写适合条件传送实现的代码

先计算一个条件操作的两种结果，然后再根据条件是否满足从而选取一个。只有在一些受限制的情况下，这种策略才可行，但是如果可行，就可以用一条简单的条件传送指令来实现它。条件传送指令更好地匹配了现代处理器的性能特征；

基于条件数据传送的代码比基于条件控制转移的代码性能好（流水线）；

避免进行分支预测，根据分支计算结果，而是将两种结果都计算出来，再赋值；

命令式（判断），功能式（赋值）；

 

*** 理解存储器性能

大数据加载和存储；读写相关；相关链，关键路径；

 

*** 性能提高技术

（1）高级设计：避免使用会渐进的产生糟糕性能的算法或编码技术（代码移动）；

（2）基本编码原则：

避免限制优化的因素（不安全因素）；

消除连续的函数调用（减少调用开销）；

消除不必要的存储器引用（避免每一次的读写操作）；

（3）低级优化

循环展开，降低开销，使得进一步优化成为可能（循环展开多路并行）；

通过使用例如多个累积变量和重新结合等技术，找到方法提高指令集并行（并行）；

用功能的风格重写条件操作，使得编译采用条件数据传送（条件数据传送，避免条件选择）；

（4）检查代码确保没有引入错误（基本要求）；

 

*** 确认和消除性能瓶颈

程序剖析，确定程序各部分需要的时间；

使用剖析程序指导优化；

 

*** Amdahl定律

要想大幅度提高整个系统的速度，必须提高整个系统很大一部分的速度；

 

*** 优化程序性能

保存在同一个数据 cache 中避免读取多次

空间局部性

寄存器中取数，不要有太多参数

暂时用不上的变量不要初始化

避免重复计算，计算保存直接使用

条件判断语句顺序调整

减少函数调用层次

优化需确保没有改变结果的正确性

多重循环，将大循环放在外面

在循环中不要使用try  catch

循环内不要创建大量的临时变量

使用局部变量

 

*** 程序优化方式

combine1，使用抽象的-O1方法优化

combine2，移动vec_length至循环外面

combine3，直接数据访问，避免过程调用；

combine4，累积在临时变量中；无展开

combine5，展开两次，三次；

combine6，展开2次，二路并行

combine7，展开2次，重新结合

 

*** 问题思考方式

发现提出问题：工具使用，检测程序性能（如何结合底层写出高效应用程序）

定义分析问题：找到问题位置

解决问题：代码优化，逻辑判断（处理器结构，高性能程序设计）

文档报告（总结）

具体事例：根据以上原则优化


写应用程序时怎样才能更有效的结合到底层的架构

指针，考虑到是否有存储器别名使用，是否指向同一位置

使用寄存器而非存储器，保存在临时变量中而不是每一次读取

                                   -------->存储器访问需要更多周期，速度慢

循环下标使用                        --------->空间局部性

指令执行寻找关键路径，结合判断      ---------->指令执行有所差异，找到关键路径

指令并行，变量重新结合              --------->考虑变量存放

书写易于被翻译为条件数据传送的代码  -------->减少分支预测失败

数据加载和存储

 
编写代码时注意一些方面

编译器设计



** 可优化性能点

性能点：
    I/O，系统调用，并发/锁，内存分配，内存拷贝，函数调用消耗，编译优化，算法

*** I/O 性能优化

I/O性能主要耗费点：系统调用，磁盘读写，网络通讯等。优化点：减少系统调用次数，减少磁盘读写次数，减少
阻塞等待。+优化手段：
+ 使用非阻塞模式
+ 使用带缓存的I/O，减少磁盘读写次数
+ I/O多路复用，select/poll/epoll
+ 异步I/O


*** 系统调用

耗费点：用户态和系统态切换时耗。
优化点：减少不必要的系统调用。
优化手段：
+ I/O操作，根据具体情况，使用 stdio 库代替 read/write
+ 缩减不必要的系统调用


*** 并发/锁

并发处理（多线程、多进程）在一定条件下可提升性能，但如果存在共享资源，则需要有互斥锁的开销。锁的优化：
+ 使用线程本地变量，避免存在共享资源
+ 减少锁的粒度
+ 无锁算法，如使用 atomic 实现的无所队列
+ 算法上减少对共享资源的访问, 如多版本算法


*** 内存分配

涉及系统调用和系统内存分配的锁操作。优化点：减少内存分配/释放的次数和频繁度优化手段：
+ 一次分配多次使用，如内存池
+ 系统内存分配替代库，如tcmalloc提高多线程环境内存分配
+ 提升对象重用程度，避免重复构造和析构


*** 内存拷贝

减少内存的拷贝操作。优化手段：
+ 利用指针、引用代替数值拷贝
+ 写时复制技术，两个对象同时引用一份数据，只有当其中一个对象需要改写数据时，才拷贝出一个数据副本。
  （std::string 采用写时复制, 因此一般情况下函数按值传递和返回 std::string，不存在字符串复制操作）


*** 函数调用消耗

函数调用时存在栈分配初始化以及后续的栈回收操作。优化手段：简单的函数，使用宏或内联方式


*** 编译优化

使用编译器的优化选项，带来额外的性能提升


*** 算法

针对特定的需求提升算法优化程度，如减少循环处理次数，使用高性能排序和搜索算法等。

** GCC -O 优化

最近做一个算法的GPU加速，发现实际上使用gcc的-O3(最高级编译优化)选项，可以获得很高的加速比，我的程序里达到了3倍的样子，有时效果甚至比GPU加速好。因此小小学习了下GNU的编译优化。
附言一句，在进行调试的时候，最好关闭编译优化，不然程序自动优化，执行的步骤可能稍有变化。

GNU编译器提供-O选项供程序优化使用:
-O 提供基础级别的优化
-O2 提供更加高级的代码优化,会占用更长的编译时间
-O3 提供最高级的代码优化
不同的优化级别使用的优化技术也可以单独的应用于代码。 可以使用-f命令行选项引用每个
单独的优化技术。

*** 编译器优化级别 1
在优化的第一个级别执行基础代码的优化。 这个级别试图执行9种单独的优化功能：
-fdefer-pop: 这种优化技术与汇编语言代码在函数完成时如何进行操作有关。 一般
情况下, 函数的输入值被保存在堆栈中并且被函数访问。 函数返回时, 输入值还在
堆栈中。 一般情况下, 函数返回之后, 输入值被立即弹出堆栈。这样做会使堆栈中
的内容有些杂乱。

-fmerge-constans: 使用这种优化技术, 编译器试图合并相同的常量. 这一特性有
时候会导致很长的编译时间, 因为编译器必须分析c或者c++程序中用到的每个常量，
并且相互比较他们.

-fthread-jumps: 使用这种优化技术与编译器如果处理汇编代码中的条件和非条件
分支有关。 在某些情况下, 一条跳转指令可能转移到另一条分支语句。 通过一连串
跳转, 编译器确定多个跳转之间的最终目标并且把第一个跳转重新定向到最终目标。

-floop-optimize: 通过优化如何生成汇编语言中的循环， 编译器可以在很大程序上
提高应用程序的性能。 通常, 程序由很多大型且复杂的循环构成。 通过删除在循环
内没有改变值的变量赋值操作, 可以减少循环内执行指令的数量, 在很大程度上提高
性能。 此外优化那些确定何时离开循环的条件分支， 以便减少分支的影响。

-fif-conversion: if-then语句应该是应用程序中仅次于循环的最消耗时间的部分。
简单的if-then语句可能在最终的汇编语言代码中产生众多的条件分支。 通过减少
或者删除条件分支, 以及使用条件传送 设置标志和使用运算技巧来替换他们, 编译
器可以减少if-then语句中花费的时间量。

-fif-conversion2: 这种技术结合更加高级的数学特性， 减少实现if-then语句所
需的条件分支。

-fdelayed-branch: 这种技术试图根据指令周期时间重新安排指令。 它还试图把
尽可能多的指令移动到条件分支前, 以便最充分的利用处理器的治理缓存。

-fguess-branch-probability: 就像其名称所暗示的, 这种技术试图确定条件分支最可
能的结果, 并且相应的移动指令, 这和延迟分支技术类似。 因为在编译时预测代码的安排，
所以使用这一选项两次编译相同的c或者c++代码很可能会产生不同的汇编语言代码， 这取决
于编译时编译器认为会使用那些分支。 因为这个原因, 很多程序员不喜欢采用这个特性, 并且
专门地使用-fno-guess-branch-probability选项关闭这个特性

-fcprop-registers: 因为在函数中把寄存器分配给变量, 所以编译器执行第二次检查以便减少
调度依赖性(两个段要求使用相同的寄存器)并且删除不必要的寄存器复制操作。

*** 编译器优化级别 2
结合了第一个级别的所有优化技术, 再加上一下一些优化：
-fforce-mem: 这种优化再任何指令使用变量前, 强制把存放再内存位置中的所有变量都复制到寄存器
中。 对于只涉及单一指令的变量, 这样也许不会有很大的优化效果. 但是对于再很多指令(必须数学操作)
中都涉及到的变量来说, 这会时很显著的优化, 因为和访问内存中的值相比 ,处理器访问寄存器中的值要
快的多。

-foptimize-sibling-calls: 这种技术处理相关的和/或者递归的函数调用。 通常, 递归的函数调用
可以被展开为一系列一般的指令， 而不是使用分支。 这样处理器的指令缓存能够加载展开的指令并且
处理他们, 和指令保持为需要分支操作的单独函数调用相比, 这样更快。

-fstrength-reduce: 这种优化技术对循环执行优化并且删除迭代变量。 迭代变量是捆绑到循环计数器
的变量, 比如使用变量, 然后使用循环计数器变量执行数学操作的for-next循环。

-fgcse： 这种技术对生成的所有汇编语言代码执行全局通用表达式消除历程。 这些优化操作试图分析
生成的汇编语言代码并且结合通用片段， 消除冗余的代码段。如果代码使用计算性的goto, gcc指令推荐
使用-fno-gcse选项。

-fcse-follow-jumps: 这种特别的通用子表达式消除技术扫描跳转指令, 查找程序中通过任何其他途径都不
会到达的目标代码。 这种情况最常见的例子就式if-then-else语句的else部分。

-frerun-cse-after-loop: 这种技术在对任何循环已经进行过优化之后重新运行通用子表达式消除例程。
这样确保在展开循环代码之后更进一步地优化还编代码。

-fdelete-null-pointer-checks: 这种优化技术扫描生成的汇编语言代码, 查找检查空指针的代码。编译
器假设间接引用空指针将停止程序。 如果在间接引用之后检查指针， 它就不可能为空。

-fextensive-optimizations: 这种技术执行从编译时的角度来说代价高昂的各种优化技术，但是它可能
对运行时的性能产生负面影响。

-fregmove: 编译器试图重新分配mov指令中使用的寄存器, 并且将其作为其他指令操作数, 以便最大化
捆绑的寄存器的数量。

-fschedule-insns: 编译器将试图重新安排指令, 以便消除等待数据的处理器。 对于在进行浮点运算时有
延迟的处理器来说， 这使处理器在等待浮点结果时可以加载其他指令。

-fsched-interblock: 这种技术使编译器能够跨越指令块调度指令。 这可以非常灵活地移动指令以便等待
期间完成的工作最大化。

-fcaller-saves: 这个选项指示编译器对函数调用保存和恢复寄存器, 使函数能够访问寄存器值, 而且不必
保存和恢复他们。 如果调用多个函数, 这样能够节省时间, 因为只进行一次寄存器的保存和恢复操作, 而
不是在每个函数调用中都进行。

-fpeephole2: 这个选项允许进行任何计算机特定的观察孔优化。

-freorder-blocks: 这种优化技术允许重新安排指令块以便改进分支操作和代码局部性。

-fstrict-aliasing: 这种技术强制实行高级语言的严格变量规则。 对于c和c++程序来说, 它确保不在数据
类型之间共享变量. 例如, 整数变量不和单精度浮点变量使用相同的内存位置。

-funit-at-a-time: 这种优化技术指示编译器在运行优化例程之前读取整个汇编语言代码。 这使编译器可以
重新安排不消耗大量时间的代码以便优化指令缓存。 但是, 这会在编译时花费相当多的内存, 对于小型计算机可能
是一个问题。

-falign-functions: 这个选项用于使函数对准内存中特定边界的开始位置。大多数处理器按照页面读取内存，
并且确保全部函数代码位于单一内存页面内, 就不需要叫化代码所需的页面。

-fcrossjumping: 这是对跨越跳转的转换代码处理， 以便组合分散在程序各处的相同代码。 这样可以减少
代码的长度， 但是也许不会对程序性能有直接影响。

*** 编译器优化级别 3
它整合了第一和第二级别中的左右优化技巧, 还包括一下优化:
-finline-functions: 这种优化技术不为函数创建单独的汇编语言代码，而是把函数代码包含在调度程序的
代码中。 对于多次被调用的函数来说, 为每次函数调用复制函数代码。 虽然这样对于减少代码长度不利, 但是
通过最充分的利用指令缓存代码, 而不是在每次函数调用时进行分支操作, 可以提高性能。

-fweb: 构建用于保存变量的伪寄存器网络。 伪寄存器包含数据, 就像他们是寄存器一样, 但是可以使用各种
其他优化技术进行优化, 比如cse和loop优化技术。
